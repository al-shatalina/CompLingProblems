{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fad453",
   "metadata": {},
   "source": [
    "# Домашнее задание № 4. Языковые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d056af4",
   "metadata": {},
   "source": [
    "## Задание 1 (8 баллов)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f532a8",
   "metadata": {},
   "source": [
    "В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de743d1d",
   "metadata": {},
   "source": [
    "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
    "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели. \n",
    "Можно использовать данные из семинара или любые другие (можно брать только часть текста, если считается слишком долго). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
    "\n",
    "\n",
    "Подсказки:  \n",
    "    - нужно будет добавить еще один тэг \\<start>  \n",
    "    - можете использовать тот же подход с матрицей вероятностей, но по строкам хронить биграмы, а по колонкам униграммы \n",
    "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так)\n",
    "    - у вас будут словари с индексами биграммов и униграммов, не перепутайте их при переводе индекса в слово - словарь биграммов будет больше словаря униграммов и все индексы из униграммного словаря будут формально подходить для словаря биграммов (не будет ошибки при id2bigram[unigram_id]), но маппинг при этом будет совершенно неправильным "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d078056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6afcef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text\n",
    "\n",
    "\n",
    "def ngrammer(tokens, n=3):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "488198d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "dvach = codecs.open( \"lenta.txt\", \"r\", \"utf_8_sig\" ).read() \n",
    "\n",
    "norm_news = normalize(news)\n",
    "\n",
    "vocab_news = Counter(norm_news)\n",
    "\n",
    "probas_news = Counter({word:c/len(norm_news) for word, c in vocab_news.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a4ce425",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_news = [['<start>','<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(news[:5000000])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8798ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams_news = Counter()\n",
    "bigrams_news = Counter()\n",
    "threegrams_news = Counter()\n",
    "\n",
    "for sentence in sentences_news:\n",
    "    unigrams_news.update(sentence)\n",
    "    bigrams_news.update(ngrammer(sentence,2))\n",
    "    threegrams_news.update(ngrammer(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acf8b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix, csr_matrix, csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c22c53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_news = lil_matrix((len(bigrams_news), \n",
    "                        len(unigrams_news)))\n",
    "\n",
    "id2word_news_1 = list(unigrams_news)\n",
    "word2id_news_1 = {word:i for i, word in enumerate(id2word_news_1)}\n",
    "\n",
    "id2word_news_2 = list(bigrams_news)\n",
    "word2id_news_2 = {word:i for i, word in enumerate(id2word_news_2)}\n",
    "\n",
    "\n",
    "for ngram in threegrams_news:\n",
    "    word1, word2, word3 = ngram.split()\n",
    "    bigram = word1 + \" \" + word2\n",
    "    matrix_news[word2id_news_2[bigram], word2id_news_1[word1]] =  (threegrams_news[ngram]/\n",
    "                                                                     bigrams_news[bigram])\n",
    "    \n",
    "matrix_news = csc_matrix(matrix_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "19fe6e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (np.int32(0), np.int32(0))\t3.1006790487116676e-05\n",
      "  (np.int32(1), np.int32(0))\t0.2\n",
      "  (np.int32(10), np.int32(0))\t1.0\n",
      "  (np.int32(22), np.int32(0))\t0.0003056234718826406\n",
      "  (np.int32(30), np.int32(0))\t0.004424778761061947\n",
      "  (np.int32(40), np.int32(0))\t0.5\n",
      "  (np.int32(54), np.int32(0))\t0.125\n",
      "  (np.int32(76), np.int32(0))\t1.0\n",
      "  (np.int32(82), np.int32(0))\t0.0032258064516129032\n",
      "  (np.int32(101), np.int32(0))\t0.0014619883040935672\n",
      "  (np.int32(122), np.int32(0))\t0.3333333333333333\n",
      "  (np.int32(149), np.int32(0))\t1.0\n",
      "  (np.int32(204), np.int32(0))\t0.01818181818181818\n",
      "  (np.int32(212), np.int32(0))\t0.00038804811796662784\n",
      "  (np.int32(228), np.int32(0))\t0.008403361344537815\n",
      "  (np.int32(243), np.int32(0))\t0.03125\n",
      "  (np.int32(259), np.int32(0))\t1.0\n",
      "  (np.int32(273), np.int32(0))\t0.004975124378109453\n",
      "  (np.int32(282), np.int32(0))\t1.0\n",
      "  (np.int32(288), np.int32(0))\t0.004329004329004329\n",
      "  (np.int32(303), np.int32(0))\t1.0\n",
      "  (np.int32(323), np.int32(0))\t1.0\n",
      "  (np.int32(389), np.int32(0))\t1.0\n",
      "  (np.int32(402), np.int32(0))\t1.0\n",
      "  (np.int32(410), np.int32(0))\t1.0\n",
      "  :\t:\n",
      "  (np.int32(380231), np.int32(71961))\t1.0\n",
      "  (np.int32(380233), np.int32(71962))\t1.0\n",
      "  (np.int32(380235), np.int32(71963))\t1.0\n",
      "  (np.int32(380244), np.int32(71964))\t1.0\n",
      "  (np.int32(380246), np.int32(71965))\t1.0\n",
      "  (np.int32(380247), np.int32(71966))\t1.0\n",
      "  (np.int32(380253), np.int32(71967))\t1.0\n",
      "  (np.int32(380255), np.int32(71968))\t1.0\n",
      "  (np.int32(380261), np.int32(71969))\t1.0\n",
      "  (np.int32(380263), np.int32(71970))\t1.0\n",
      "  (np.int32(380265), np.int32(71971))\t1.0\n",
      "  (np.int32(380267), np.int32(71972))\t1.0\n",
      "  (np.int32(380285), np.int32(71974))\t1.0\n",
      "  (np.int32(380292), np.int32(71975))\t1.0\n",
      "  (np.int32(380294), np.int32(71976))\t1.0\n",
      "  (np.int32(380299), np.int32(71977))\t1.0\n",
      "  (np.int32(380304), np.int32(71978))\t1.0\n",
      "  (np.int32(380305), np.int32(71979))\t1.0\n",
      "  (np.int32(380310), np.int32(71981))\t1.0\n",
      "  (np.int32(380314), np.int32(71982))\t1.0\n",
      "  (np.int32(380316), np.int32(71983))\t1.0\n",
      "  (np.int32(380326), np.int32(71984))\t1.0\n",
      "  (np.int32(380336), np.int32(71985))\t1.0\n",
      "  (np.int32(380341), np.int32(71986))\t1.0\n",
      "  (np.int32(380345), np.int32(71987))\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(matrix_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "99734064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_temperature(probas, temperature):\n",
    "    # логарифмирование и деление на температуру\n",
    "    log_probas = np.log(np.maximum(probas, 1e-10))  \n",
    "    adjusted_log_probas = log_probas / temperature\n",
    "    # чтобы получить честные вероятности, нужно применить софтмакс\n",
    "    exp_probas = np.exp(adjusted_log_probas)\n",
    "    adjusted_probabilities = exp_probas / np.sum(exp_probas)\n",
    "    return adjusted_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "352ce46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(matrix, id2word, word2id, n=100, start='<start> <start>', temperature = 0.1):\n",
    "    text = []\n",
    "    current_idx = word2id[start]\n",
    "    for i in range(n):\n",
    "        \n",
    "        chosen_idx = np.random.choice(matrix.shape[1], p=apply_temperature(matrix[current_idx].toarray()[0], temperature=temperature))\n",
    "        chosen = id2word[chosen_idx]\n",
    "        text.append(chosen)\n",
    "\n",
    "        if id2word[chosen_idx] == '<end>':\n",
    "            chosen_idx = word2id['<start> <start>']\n",
    "        current_idx = chosen_idx\n",
    "        print(current_idx)\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9e0125d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "<start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start> <start>\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_news, id2word_news_1, word2id_news_2).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a8dd5",
   "metadata": {},
   "source": [
    "## Задание № 2* (2 балла). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f733858c",
   "metadata": {},
   "source": [
    "Измените функцию generate_with_beam_search так, чтобы она работала с моделью, которая учитывает два предыдущих слова. \n",
    "Сравните получаемый результат с первым заданием. \n",
    "Также попробуйте начинать генерацию не с нуля (подавая \\<start> \\<start>), а с какого-то промпта. Но помните, что учитываться будут только два последних слова, так что не делайте длинные промпты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426746a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
