{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98604cb",
   "metadata": {},
   "source": [
    "Домашку будет легче делать в колабе (убедитесь, что у вас runtype с gpu)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c422aa0",
   "metadata": {},
   "source": [
    "# Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a72790",
   "metadata": {},
   "source": [
    "Обучите word2vec модели с негативным семплированием (cbow и skip-gram) аналогично тому, как это было сделано в семинаре. Вам нужно изменить следующие пункты: \n",
    "1) добавьте лемматизацию в предобработку (любым способом)  \n",
    "2) измените размер окна в большую или меньшую сторону\n",
    "3) измените размерность итоговых векторов\n",
    "\n",
    "Выберете несколько не похожих по смыслу слов (не таких как в семинаре), и протестируйте полученные эмбединги (найдите ближайшие слова и оцените качество, как в семинаре). \n",
    "Постарайтесь обучать модели как можно дольше и на как можно большем количестве данных. (Но если у вас мало времени или ресурсов, то допустимо взять поменьше данных и поставить меньше эпох)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde5fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "%matplotlib inline\n",
    "\n",
    "import pymorphy3\n",
    "morph = pymorphy3.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f71d7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "# os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "# torch.set_default_device('cpu')\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e894f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "file = codecs.open('wiki_data.txt', \"r\", \"utf-8\" )\n",
    "wiki = file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7f52250",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=10000)\n",
    "svd = TruncatedSVD(200)\n",
    "\n",
    "X = cv.fit_transform(wiki)\n",
    "X_svd = svd.fit_transform(X)\n",
    "\n",
    "embeddings = svd.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b8fc32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = cv.get_feature_names_out()\n",
    "word2id = {word:i for i,word in enumerate(id2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2332325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(text):\n",
    "    tokens = re.sub('#+', ' ', text.lower()).split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    tokens = [morph.parse(token)[0] for token in tokens]\n",
    "    tokens = [token.normal_form for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67edfb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c7f635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20003/20003 [05:40<00:00, 58.80it/s] \n"
     ]
    }
   ],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in tqdm(wiki):\n",
    "    vocab.update(preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e0b99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vocab = set()\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] > 30:\n",
    "        filtered_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dffc910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {'PAD':0}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)\n",
    "\n",
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4e7f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for text in wiki:\n",
    "    tokens = preprocess(text)\n",
    "    if not tokens:\n",
    "        continue\n",
    "    ids = [word2id[token] for token in tokens if token in word2id]\n",
    "    sentences.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c8bab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39d146cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip gram\n",
    "def gen_batches_sg(sentences, window = 3, batch_size=1000):\n",
    "    \n",
    "    # параметр window задает его целиком\n",
    "    # нам нужно поделить его пополам на левую и правую часть\n",
    "    # когда делится неровно, то левая часть больше на 1\n",
    "    left_context_length = (window/2).__ceil__() # округлить в большую сторону\n",
    "    right_context_length = window // 2 # округлить в меньшую сторону\n",
    "    \n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            for i in range(len(sent)-1):\n",
    "                word = sent[i]\n",
    "                context = sent[max(0, i-left_context_length):i] + sent[i+1:i+right_context_length]\n",
    "                for context_word in context:\n",
    "                    X_target.append(word)\n",
    "                    X_context.append(context_word)\n",
    "                    y.append(1)\n",
    "                    \n",
    "                    X_target.append(word)\n",
    "                    X_context.append(np.random.randint(vocab_size))\n",
    "                    y.append(0)\n",
    "                    \n",
    "                    if len(X_target) >= batch_size:\n",
    "                        X_target = np.array(X_target)\n",
    "                        X_context = np.array(X_context)\n",
    "                        y = np.array(y)\n",
    "                        yield ((X_target, X_context), y)\n",
    "                        X_target = []\n",
    "                        X_context = []\n",
    "                        y = []\n",
    "\n",
    "# # cbow \n",
    "def gen_batches_cbow(sentences, window = 3, batch_size=1000):\n",
    "    \n",
    "    # параметр window задает его целиком\n",
    "    # нам нужно поделить его пополам на левую и правую часть\n",
    "    # когда делится неровно, то левая часть больше на 1\n",
    "    left_context_length = (window/2).__ceil__() # округлить в большую сторону\n",
    "    right_context_length = window // 2 # округлить в меньшую сторону\n",
    "    \n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            for i in range(len(sent)-1):\n",
    "                word = sent[i]\n",
    "                context = sent[max(0, i-left_context_length):i] + sent[i+1:i+right_context_length]\n",
    "\n",
    "                X_target.append(word)\n",
    "                X_context.append(context)\n",
    "                y.append(1)\n",
    "                \n",
    "                X_target.append(np.random.randint(vocab_size))\n",
    "                X_context.append(context)\n",
    "                y.append(0)\n",
    "\n",
    "                if len(X_target) == batch_size:\n",
    "                    X_target = np.array(X_target)\n",
    "                    X_context = keras.preprocessing.sequence.pad_sequences(X_context, maxlen=window)\n",
    "                    y = np.array(y)\n",
    "                    yield ((X_target, X_context), y)\n",
    "                    X_target = []\n",
    "                    X_context = []\n",
    "                    y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48e30f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_target = keras.layers.Input(shape=(1,))\n",
    "inputs_context = keras.layers.Input(shape=(1,))\n",
    "\n",
    "\n",
    "embeddings_target = keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_target, )\n",
    "embeddings_context = keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_context, )\n",
    "\n",
    "target = keras.layers.Flatten()(embeddings_target)\n",
    "context = keras.layers.Flatten()(embeddings_context)\n",
    "\n",
    "dot = keras.layers.Dot(1)([target, context])\n",
    "outputs = keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model = keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c7c318d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 32ms/step - accuracy: 0.7921 - loss: 0.4546 - val_accuracy: 0.8361 - val_loss: 0.3890\n",
      "Epoch 2/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 25ms/step - accuracy: 0.8420 - loss: 0.3689 - val_accuracy: 0.8491 - val_loss: 0.3549\n",
      "Epoch 3/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 28ms/step - accuracy: 0.8544 - loss: 0.3386 - val_accuracy: 0.8559 - val_loss: 0.3380\n",
      "Epoch 4/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 38ms/step - accuracy: 0.8601 - loss: 0.3251 - val_accuracy: 0.8502 - val_loss: 0.3551\n",
      "Epoch 5/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 34ms/step - accuracy: 0.8635 - loss: 0.3148 - val_accuracy: 0.8577 - val_loss: 0.3395\n",
      "Epoch 6/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 22ms/step - accuracy: 0.8709 - loss: 0.2980 - val_accuracy: 0.8402 - val_loss: 0.3820\n",
      "Epoch 7/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 20ms/step - accuracy: 0.8739 - loss: 0.2912 - val_accuracy: 0.8390 - val_loss: 0.3867\n",
      "Epoch 8/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 31ms/step - accuracy: 0.8778 - loss: 0.2812 - val_accuracy: 0.8600 - val_loss: 0.3441\n",
      "Epoch 9/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 30ms/step - accuracy: 0.8811 - loss: 0.2747 - val_accuracy: 0.8450 - val_loss: 0.3985\n",
      "Epoch 10/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 29ms/step - accuracy: 0.8824 - loss: 0.2720 - val_accuracy: 0.8395 - val_loss: 0.4119\n",
      "Epoch 11/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 19ms/step - accuracy: 0.8862 - loss: 0.2635 - val_accuracy: 0.8323 - val_loss: 0.4622\n",
      "Epoch 12/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 22ms/step - accuracy: 0.8875 - loss: 0.2606 - val_accuracy: 0.8216 - val_loss: 0.4711\n",
      "Epoch 13/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 38ms/step - accuracy: 0.8906 - loss: 0.2539 - val_accuracy: 0.8499 - val_loss: 0.4138\n",
      "Epoch 14/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 36ms/step - accuracy: 0.8908 - loss: 0.2537 - val_accuracy: 0.8292 - val_loss: 0.4740\n",
      "Epoch 15/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 30ms/step - accuracy: 0.8916 - loss: 0.2525 - val_accuracy: 0.8288 - val_loss: 0.5008\n",
      "Epoch 16/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 20ms/step - accuracy: 0.8941 - loss: 0.2467 - val_accuracy: 0.8442 - val_loss: 0.4434\n",
      "Epoch 17/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 24ms/step - accuracy: 0.8939 - loss: 0.2471 - val_accuracy: 0.8404 - val_loss: 0.4690\n",
      "Epoch 18/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 35ms/step - accuracy: 0.8993 - loss: 0.2358 - val_accuracy: 0.8419 - val_loss: 0.4739\n",
      "Epoch 19/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 31ms/step - accuracy: 0.8968 - loss: 0.2413 - val_accuracy: 0.8200 - val_loss: 0.5787\n",
      "Epoch 20/20\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 20ms/step - accuracy: 0.8960 - loss: 0.2432 - val_accuracy: 0.8372 - val_loss: 0.5058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x289f40bb890>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(gen_batches_sg(sentences[:19000]),\n",
    "          validation_data=gen_batches_sg(sentences[19000:]),\n",
    "          batch_size=1000,\n",
    "          steps_per_epoch=10000,\n",
    "          validation_steps=30,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9b8a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, embeddings):\n",
    "    similar = [id2word[i] for i in \n",
    "               cosine_distances(embeddings[word2id[word]].reshape(1, -1), embeddings).argsort()[0][:5]]\n",
    "    return similar\n",
    "#сделала топ 5 вместо топ 10 для удобства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fc2345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1f493ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['жизнь', 'благосостояние', 'страдание', 'процветание', 'покойный'] ['боль', 'мышечный', 'зуд', 'синдром', 'аллергический']\n"
     ]
    }
   ],
   "source": [
    "print (most_similar('жизнь', embeddings), most_similar('боль', embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ce66132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cbow negative sampling\n",
    "inputs_target = keras.layers.Input(shape=(1,))\n",
    "inputs_context = keras.layers.Input(shape=(20,))\n",
    "\n",
    "\n",
    "embeddings_target = keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_target, )\n",
    "embeddings_context = keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_context, )\n",
    "\n",
    "target = keras.layers.Flatten()(embeddings_target)\n",
    "context = keras.layers.Lambda(lambda x: x.sum(axis=1))(embeddings_context)\n",
    "dot = keras.layers.Dot(1)([target, context])\n",
    "\n",
    "# полученную близость нужно преобразовать в вероятность\n",
    "# когда она одна используется не софтмакс и сигмоида\n",
    "outputs = keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model = keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62eedefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 23ms/step - accuracy: 0.8233 - loss: 0.3965 - val_accuracy: 0.8813 - val_loss: 0.2930\n",
      "Epoch 2/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 23ms/step - accuracy: 0.8852 - loss: 0.2822 - val_accuracy: 0.8981 - val_loss: 0.2555\n",
      "Epoch 3/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 23ms/step - accuracy: 0.9104 - loss: 0.2224 - val_accuracy: 0.8936 - val_loss: 0.2665\n",
      "Epoch 4/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 23ms/step - accuracy: 0.9194 - loss: 0.2030 - val_accuracy: 0.8975 - val_loss: 0.2664\n",
      "Epoch 5/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 23ms/step - accuracy: 0.9311 - loss: 0.1778 - val_accuracy: 0.8986 - val_loss: 0.2777\n",
      "Epoch 6/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 23ms/step - accuracy: 0.9415 - loss: 0.1550 - val_accuracy: 0.8760 - val_loss: 0.3807\n",
      "Epoch 7/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 23ms/step - accuracy: 0.9453 - loss: 0.1482 - val_accuracy: 0.8864 - val_loss: 0.3548\n",
      "Epoch 8/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 23ms/step - accuracy: 0.9526 - loss: 0.1334 - val_accuracy: 0.8822 - val_loss: 0.3934\n",
      "Epoch 9/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 24ms/step - accuracy: 0.9546 - loss: 0.1303 - val_accuracy: 0.8841 - val_loss: 0.4091\n",
      "Epoch 10/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 24ms/step - accuracy: 0.9567 - loss: 0.1266 - val_accuracy: 0.8774 - val_loss: 0.4873\n",
      "Epoch 11/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 24ms/step - accuracy: 0.9614 - loss: 0.1160 - val_accuracy: 0.8858 - val_loss: 0.4478\n",
      "Epoch 12/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 24ms/step - accuracy: 0.9621 - loss: 0.1149 - val_accuracy: 0.8873 - val_loss: 0.4388\n",
      "Epoch 13/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 23ms/step - accuracy: 0.9641 - loss: 0.1113 - val_accuracy: 0.8801 - val_loss: 0.5054\n",
      "Epoch 14/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 23ms/step - accuracy: 0.9652 - loss: 0.1086 - val_accuracy: 0.8694 - val_loss: 0.6116\n",
      "Epoch 15/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 23ms/step - accuracy: 0.9654 - loss: 0.1092 - val_accuracy: 0.8415 - val_loss: 0.7538\n",
      "Epoch 16/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 23ms/step - accuracy: 0.9673 - loss: 0.1048 - val_accuracy: 0.8820 - val_loss: 0.5568\n",
      "Epoch 17/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 23ms/step - accuracy: 0.9675 - loss: 0.1052 - val_accuracy: 0.8811 - val_loss: 0.5613\n",
      "Epoch 18/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 23ms/step - accuracy: 0.9692 - loss: 0.1007 - val_accuracy: 0.8469 - val_loss: 0.7592\n",
      "Epoch 19/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 23ms/step - accuracy: 0.9692 - loss: 0.1013 - val_accuracy: 0.8860 - val_loss: 0.5651\n",
      "Epoch 20/20\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 23ms/step - accuracy: 0.9692 - loss: 0.1020 - val_accuracy: 0.8739 - val_loss: 0.6677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x239d02b7050>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build([(None, 1), (None, 20)])\n",
    "model.fit(gen_batches_cbow(sentences[:19000], window=20),\n",
    "          validation_data=gen_batches_cbow(sentences[19000:],  window=20),\n",
    "          batch_size=1000,\n",
    "          steps_per_epoch=5000,\n",
    "          validation_steps=30,\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a679ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1ff2cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['мир', 'европа', 'история', 'чемпионат', 'турнир']\n",
      "['жизнь', 'смерть', 'забота', 'общество', 'не']\n"
     ]
    }
   ],
   "source": [
    "print(most_similar('мир', embeddings), most_similar('жизнь', embeddings), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b61b7c",
   "metadata": {},
   "source": [
    "# Задание 2 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eff080",
   "metadata": {},
   "source": [
    "Обучите 1 word2vec и 1 fastext модель в gensim. В каждой из модели нужно задать все параметры, которые мы разбирали на семинаре. Заданные значения должны отличаться от дефолтных и от тех, что мы использовали на семинаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b96ab3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\alex\\scoop\\apps\\python\\current\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\alex\\scoop\\apps\\python\\current\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\alex\\scoop\\apps\\python\\current\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\alex\\scoop\\apps\\python\\current\\lib\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\alex\\scoop\\apps\\python\\current\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\Alex\\scoop\\apps\\python\\current\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\Alex\\scoop\\apps\\python\\current\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (C:\\Users\\Alex\\scoop\\apps\\python\\current\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59a951bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11f75419",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [preprocess(text) for text in wiki]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5035bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.72 s\n",
      "Wall time: 8.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91b89b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.2 s\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             vector_size=220, \n",
    "                             min_count=42, \n",
    "                             max_vocab_size=9000,\n",
    "                             window=7,\n",
    "                             epochs=6,\n",
    "                             sample=1e-4,\n",
    "                             hs=0,\n",
    "                             negative=7,\n",
    "                             sg=1,\n",
    "                             ns_exponent=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06b908fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('любовь', 0.5137007832527161),\n",
       " ('мысль', 0.48829516768455505),\n",
       " ('писать', 0.48748597502708435),\n",
       " ('судьба', 0.46646174788475037),\n",
       " ('смерть', 0.46003371477127075),\n",
       " ('творчество', 0.43642449378967285),\n",
       " ('образ', 0.4345947206020355),\n",
       " ('весь', 0.434222012758255),\n",
       " ('сам', 0.43247854709625244),\n",
       " ('тема', 0.4323006570339203)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('жизнь')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd1cb343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 30.2 s\n",
      "Wall time: 38.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft = gensim.models.FastText(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79f97148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.9 s\n",
      "Wall time: 32.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft = gensim.models.FastText(texts, min_n=5, max_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f56b055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('жизнью»', 0.9892975091934204),\n",
       " ('alkan', 0.9850301742553711),\n",
       " ('жизнь»', 0.9648974537849426),\n",
       " ('«жизнь', 0.9555759429931641),\n",
       " ('жизни»', 0.8117483854293823),\n",
       " ('жизненно', 0.7297841906547546),\n",
       " ('«судьба', 0.6842685341835022),\n",
       " ('детство', 0.6823813319206238),\n",
       " ('«детство', 0.6570226550102234),\n",
       " ('сознание', 0.656275749206543)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar('жизнь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb928c",
   "metadata": {},
   "source": [
    "# Задание 3 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019b0d1",
   "metadata": {},
   "source": [
    "Используя датасет для классификации (labeled.csv), обучите классификатор на базе эмбеддингов. Оцените качество на отложенной выборке.   \n",
    "В качестве эмбеддинг модели вы можете использовать одну из моделей обученных в предыдущем задании или использовать одну из предобученных моделей с rusvectores (удостоверьтесь что правильно воспроизводите предобработку в этом случае!)  \n",
    "Для того, чтобы построить эмбединг целого текста, усредните вектора отдельных слов в один общий вектор. \n",
    "В качестве алгоритма классификации используйте LogisicticRegression (можете попробовать SGDClassifier, чтобы было побыстрее)  \n",
    "F1 мера должна быть выше 20%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "878b482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression as logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed908832",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "data['norm_text'] = data.comment.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa05691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6308"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in data['norm_text']:\n",
    "    vocab.update(text)\n",
    "    \n",
    "filtered_vocab = set()\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] > 5:\n",
    "        filtered_vocab.add(word)\n",
    "\n",
    "len(filtered_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da50591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_toid(tokens):\n",
    "    vec = np.zeros(w2v.vector_size)\n",
    "    for token in tokens:\n",
    "        if token in w2v.wv:\n",
    "            vec+=w2v.wv[token]\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7436c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [word_toid(text) for text in data['norm_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70747c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "748e1edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb6ff19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.70      0.79       493\n",
      "         1.0       0.57      0.86      0.69       228\n",
      "\n",
      "    accuracy                           0.75       721\n",
      "   macro avg       0.74      0.78      0.74       721\n",
      "weighted avg       0.81      0.75      0.76       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = logreg(penalty='l2', class_weight= 'balanced', max_iter= 10000)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_valid)\n",
    "print(classification_report(y_valid, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2bcb67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_proba = clf.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a9d0d778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ты, как совместившая, делишься опытом? Учту.\\n', 0.9999104553209482),\n",
       " ('Ну хочешь я стану твоим другом? Как тебя зовут? Чем увлекаешься?\\n',\n",
       "  0.9995722744880517),\n",
       " ('Я тоже. Ладно мы, у нас еще сто лет назад власть захватил открыто антирусский режим. Мордор он и есть Мордор. Но у них-то еще совсем недавно все было хорошо и никто бы не мог даже представить такого пиздеца.\\n',\n",
       "  0.9992684276337245),\n",
       " ('Ну давай. Отбери у меня нож, клоун, только я махну рукой и твои яйца разлетятся по всему арбату.\\n',\n",
       "  0.9983425860993097),\n",
       " ('Просто ник автора, наверное\\n', 0.9952993285835451),\n",
       " ('Большинство новых коттеджных поселков имеют статус садоводств, благодаря этому могут еще и сдирать по три шкуры с новых собственников на обслуживании. Причем сейчас с кризисом в загородке очень много стали продавать без подряда. У нас очень неразвита строительная экспертиза и контроль в частном домостроении, поэтому проблемных домов очень много, где люди потом годами пытаются это исправить.\\n',\n",
       "  0.9950051595595896),\n",
       " ('А я готовлю почти также, только сахар не использую вообще, а вместо него добавляю в фарш изюм - получается вкусно. Ну и без яйца в конце (хотя зачетно должно быть, только вряд ли совместимо с изюмом, надо будет попробовать так).\\n',\n",
       "  0.993939843482527),\n",
       " ('Уважаемый, да вы бредите. заварите ка как на картинке на любом заводе, где есть сварка. такая подойдёт?\\n',\n",
       "  0.9926894744759021),\n",
       " ('Для каких стан является эталоном современная система здравоохранения РФ? Для Зимбабве? Ты тупой? хохлы\\n',\n",
       "  0.9854066655857703),\n",
       " ('А почему жена не могла её послать туда же? Сказала: иди ка ты, пожилая неразумная женщина-вагина все туда же. И всё. Развернулась и ушла. А то стоит с маленьким ребенком и слушает. Мелочь тоже слушает и боится. Нет нет. Только на й. И погромче.\\n',\n",
       "  0.9832660775952713)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter({comm: prob[1] for comm, prob in zip(data.comment, preds_proba)})\n",
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c18c5a",
   "metadata": {},
   "source": [
    "# Задание 4 (2 доп балла)\n",
    "\n",
    "В тетрадку с фастекстом добавьте код для обучения с negative sampling (задача сводится к бинарной классификации) и обучите модель. Проверьте полученную модель на нескольких словах. Похожие слова должны быть похожими по смыслу и по форме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4bc990fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "def tokenize(text):\n",
    "    tokens = re.sub('#+', ' ', text.lower()).split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d138e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrammer(raw_string, n=2):\n",
    "    ngrams = []\n",
    "    raw_string = ''.join(['<', raw_string, '>'])\n",
    "    for i in range(0,len(raw_string)-n+1):\n",
    "        ngram = ''.join(raw_string[i:i+n])\n",
    "        if ngram == '<' or ngram == '>': # сами по себе <> как токены не нужны\n",
    "            continue\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "edb588fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tokens(tokens, min_ngram_size, max_ngram_size):\n",
    "    tokens_with_subwords = []\n",
    "    for token in tokens:\n",
    "        subtokens = []\n",
    "        for i in range(min_ngram_size, max_ngram_size+1):\n",
    "            if len(token) > i:\n",
    "                subtokens.extend(ngrammer(token, i))\n",
    "        tokens_with_subwords.append(subtokens)\n",
    "    return tokens_with_subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f464e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubwordTokenizer:\n",
    "    def __init__(self, ngram_range=(1,1), min_count=5):\n",
    "        self.min_ngram_size, self.max_ngram_size = ngram_range\n",
    "        self.min_count = min_count\n",
    "        self.subword_vocab = None\n",
    "        self.fullword_vocab = None\n",
    "        self.vocab = None\n",
    "        self.id2word = None\n",
    "        self.word2id = None\n",
    "\n",
    "    def build_vocab(self, texts):\n",
    "        # чтобы построить словарь нужно пройти по всему корпусу и собрать частоты всех уникальных слов и нграммов\n",
    "        unfiltered_subword_vocab = Counter()\n",
    "        unfiltered_fullword_vocab = Counter()\n",
    "        for text in texts:\n",
    "            tokens = tokenize(text)\n",
    "            unfiltered_fullword_vocab.update(tokens)\n",
    "            subwords_per_token = split_tokens(tokens, self.min_ngram_size, self.max_ngram_size)\n",
    "            for subwords in subwords_per_token:\n",
    "                # в одном слове могут быть одинаковые нграммы поэтому возьмем только уникальные\n",
    "                unfiltered_subword_vocab.update(set(subwords))\n",
    "\n",
    "        self.fullword_vocab = set()\n",
    "        self.subword_vocab = set()\n",
    "\n",
    "        # теперь отфильтруем по частоте\n",
    "        for word, count in unfiltered_fullword_vocab.items():\n",
    "            if count >= self.min_count:\n",
    "                self.fullword_vocab.add(word)\n",
    "        # для нграммов сделаем порог побольше чтобы не создавать слишком много нграммов\n",
    "        # и учитывать только действительно частотные\n",
    "        for word, count in unfiltered_subword_vocab.items():\n",
    "            if count >= (self.min_count * 100):\n",
    "                self.subword_vocab.add(word)\n",
    "\n",
    "        # общий словарь\n",
    "        self.vocab = self.fullword_vocab | self.subword_vocab\n",
    "        self.id2word = {i:word for i,word in enumerate(self.vocab)}\n",
    "        self.word2id = {word:i for i,word in self.id2word.items()}\n",
    "\n",
    "    def subword_tokenize(self, text):\n",
    "        if self.vocab is None:\n",
    "            raise AttributeError('Vocabulary is not built!')\n",
    "        # разбиваем на токены\n",
    "        tokens = tokenize(text) \n",
    "        # каждый токен разбиваем на символьные нграммы\n",
    "        tokens_with_subwords = split_tokens(tokens, self.min_ngram_size, self.max_ngram_size)\n",
    "        # оставляет только токены и нграммы которые есть в словаре\n",
    "        only_vocab_tokens_with_subwords = []\n",
    "        for full_token, sub_tokens in zip(tokens, tokens_with_subwords):\n",
    "            filtered = []\n",
    "            if full_token in self.vocab:\n",
    "                # само слово и нграммы хранятся в одном списке \n",
    "                # но слово будет всегда первым в списке\n",
    "                filtered.append(full_token)\n",
    "            filtered.extend([subtoken for subtoken in set(sub_tokens) if subtoken in self.vocab])\n",
    "            only_vocab_tokens_with_subwords.append(filtered)\n",
    "\n",
    "        return only_vocab_tokens_with_subwords\n",
    "\n",
    "    def encode(self, subword_tokenized_text):\n",
    "        # маппим токены и нграммы в их индексы в словаре\n",
    "        encoded_text = []\n",
    "        for token in subword_tokenized_text:\n",
    "            if not token:\n",
    "                continue\n",
    "            encoded_text.append([self.word2id[token[0]]] + [self.word2id[t] for t in set(token[1:]) if t in self.word2id and t != token[0]])\n",
    "        return encoded_text\n",
    "\n",
    "    def __call__(self, text):\n",
    "        return self.encode(self.subword_tokenize(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b673c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SubwordTokenizer(ngram_range=(2,4), min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b678290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.build_vocab(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d437a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_gen_batches_ft(sentences, tokenizer, window = 5, batch_size=1000, maxlen=20):\n",
    "    \n",
    "    vocab_size= len(tokenizer.vocab)\n",
    "    left_context_length = (window/2).__ceil__() \n",
    "    right_context_length = window // 2 \n",
    "    \n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            sent = tokenizer(sent)\n",
    "            for i in range(len(sent)-1):\n",
    "                word_with_subtokens = sent[i]\n",
    "                context = sent[max(0, i-left_context_length):i] + sent[i+1:i+right_context_length]\n",
    "                for context_word_with_subtokens in context:\n",
    "                    # целевой токен всегда только целый\n",
    "                    # мы берем первый токен из списка который вернул токенайзер\n",
    "                    # там у нас будет лежать целое слово\n",
    "                    only_full_word_context_token = context_word_with_subtokens[0]\n",
    "                    X_target.append(word_with_subtokens)\n",
    "                    X_context.append(only_full_word_context_token )\n",
    "                    y.append(1)\n",
    "                    \n",
    "                    X_target.append(word_with_subtokens)\n",
    "                    X_context.append(np.random.randint(vocab_size))\n",
    "                    y.append(0)\n",
    "                    \n",
    "                    if len(X_target) >= batch_size:\n",
    "                        # тут нам понадобится паддинг так как количество сивольных нграммов будет зависеть от длины токенов\n",
    "                        X_target = np.array(keras.preprocessing.sequence.pad_sequences(X_target, maxlen=maxlen))\n",
    "                        X_context = np.array(X_context)\n",
    "                        y = np.array(y)\n",
    "                        yield ((X_target, X_context), y)\n",
    "                        X_target = []\n",
    "                        X_context = []\n",
    "                        y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "630203d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = neg_gen_batches_ft(wiki, tokenizer, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "945a58c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_target = keras.layers.Input(shape=(20,))\n",
    "inputs_context = keras.layers.Input(shape=(1,))\n",
    "\n",
    "\n",
    "embeddings_target = keras.layers.Embedding(input_dim=len(tokenizer.vocab), output_dim=100)(inputs_target, )\n",
    "embeddings_context = keras.layers.Embedding(input_dim=len(tokenizer.vocab), output_dim=100)(inputs_context, )\n",
    "\n",
    "target = keras.layers.Lambda(lambda x: x.sum(axis=1))(embeddings_target)\n",
    "context = keras.layers.Lambda(lambda x: x.sum(axis=1))(embeddings_context)\n",
    "dot = keras.layers.Dot(1)([target, context])\n",
    "\n",
    "# полученную близость нужно преобразовать в вероятность\n",
    "# когда она одна используется не софтмакс и сигмоида\n",
    "outputs = keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model = keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a626e6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build((None, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3b689627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_42      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_43      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_42        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,486,000</span> │ input_layer_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_43        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,486,000</span> │ input_layer_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ lambda_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_13       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_42      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_43      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_42        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │  \u001b[38;5;34m5,486,000\u001b[0m │ input_layer_42[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_43        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │  \u001b[38;5;34m5,486,000\u001b[0m │ input_layer_43[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_26 (\u001b[38;5;33mLambda\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embedding_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_27 (\u001b[38;5;33mLambda\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ embedding_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_21 (\u001b[38;5;33mDot\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ lambda_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ lambda_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_13       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dot_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,972,000</span> (41.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,972,000\u001b[0m (41.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,972,000</span> (41.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,972,000\u001b[0m (41.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5936742d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 28ms/step - accuracy: 0.8797 - loss: 0.3014 - val_accuracy: 0.7573 - val_loss: 0.5463\n",
      "Epoch 2/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 28ms/step - accuracy: 0.8270 - loss: 0.4083 - val_accuracy: 0.7617 - val_loss: 0.5236\n",
      "Epoch 3/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.8052 - loss: 0.4434 - val_accuracy: 0.7604 - val_loss: 0.5061\n",
      "Epoch 4/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 29ms/step - accuracy: 0.8074 - loss: 0.4398 - val_accuracy: 0.7811 - val_loss: 0.5195\n",
      "Epoch 5/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 29ms/step - accuracy: 0.8143 - loss: 0.4285 - val_accuracy: 0.7821 - val_loss: 0.5141\n",
      "Epoch 6/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 29ms/step - accuracy: 0.8073 - loss: 0.4442 - val_accuracy: 0.7762 - val_loss: 0.5035\n",
      "Epoch 7/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 29ms/step - accuracy: 0.8035 - loss: 0.4549 - val_accuracy: 0.7403 - val_loss: 0.5777\n",
      "Epoch 8/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 29ms/step - accuracy: 0.7977 - loss: 0.4653 - val_accuracy: 0.7629 - val_loss: 0.5665\n",
      "Epoch 9/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 29ms/step - accuracy: 0.8112 - loss: 0.4461 - val_accuracy: 0.7627 - val_loss: 0.5355\n",
      "Epoch 10/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 29ms/step - accuracy: 0.8035 - loss: 0.4603 - val_accuracy: 0.7869 - val_loss: 0.5088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e572cdb5f0>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(neg_gen_batches_ft(wiki[:19000],tokenizer, window=10, batch_size=100),\n",
    "          validation_data=neg_gen_batches_ft(wiki[19000:], tokenizer, window=10, batch_size=100),\n",
    "          batch_size=1000,\n",
    "          steps_per_epoch=5000,\n",
    "          validation_steps=100,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "296ada83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1cedf2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.layers[2].get_weights()[0] # матрица со всеми эмбедингами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "83957e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_word_embeddings = np.zeros((len(tokenizer.fullword_vocab), 100)) # матрица с эмбедингами полных слов + нграммы\n",
    "id2word = list(tokenizer.fullword_vocab)\n",
    "\n",
    "for i, word in enumerate(tokenizer.fullword_vocab):\n",
    "    subwords = tokenizer(word)[0]\n",
    "    full_word_embeddings[i] = embeddings[[i for i in subwords]].mean(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c1210287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_ft(word, embeddings, tokenizer):\n",
    "    subwords = tokenizer(word)[0]\n",
    "    word_embedding = embeddings[[i for i in subwords]].sum(axis=0)\n",
    "    # idxs = [tokenizer.word2id[i] for i in tokenizer.fullword_vocab]\n",
    "    similar = [id2word[i] for i in \n",
    "               cosine_distances(word_embedding.reshape(1, -1), full_word_embeddings).argsort()[0][:20]]\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e4cab855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['жизнь',\n",
       " '«жизнь',\n",
       " 'жизнь»',\n",
       " 'жизнью',\n",
       " 'жизни»',\n",
       " 'жизни',\n",
       " 'жизненно',\n",
       " 'жизней',\n",
       " 'жизненной',\n",
       " 'жизненного',\n",
       " 'жизненные',\n",
       " 'жизненных',\n",
       " 'жизненный',\n",
       " 'жирным',\n",
       " 'собственниками',\n",
       " 'внутренними',\n",
       " 'предлагается',\n",
       " 'казнь',\n",
       " 'драго',\n",
       " 'предлагает']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_ft('жизнь', embeddings, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
