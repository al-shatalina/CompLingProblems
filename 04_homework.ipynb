{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48abae58",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "\n",
    "\n",
    "Выберите 5 языков в википедии (не тех, что использовались в семинаре). Скачайте по 10 случайных статей для каждого языка. Предобработайте тексты, удаляя лишние теги/отступы/разделители (если они есть). Разделите тексты на предложения и создайте датасет, в котором каждому предложению соответствует язык. Кластеризуйте тексты, используя эбмединг модель из прошлого семинара и любой алгоритм кластеризации. Проверьте качество кластеризации с помощь метрики ARI. Отдельно проанализируйте 3 ошибочно кластеризованных текста (если такие есть)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1769f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import numpy as np\n",
    "code2lang = wikipedia.languages()\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from string import digits\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44475c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['it', 'de', 'es', 'fr', 'sl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c3d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_with_disambigution(page):\n",
    "    try:\n",
    "        p = wikipedia.page(page)\n",
    "    except wikipedia.DisambiguationError as e:\n",
    "        random_option = np.random.choice(e.options)\n",
    "        p = wikipedia.page(random_option)\n",
    "    return p\n",
    "\n",
    "def get_texts_for_lang(lang, n=100): # функция для скачивания статей из википедии\n",
    "    # вот так можно зафиксировать язык\n",
    "    wikipedia.set_lang(lang)\n",
    "    wiki_content = []\n",
    "    \n",
    "    # random достает только ссылки на статьи\n",
    "    pages = wikipedia.random(n)\n",
    "    \n",
    "    for page_name in pages:\n",
    "        try:\n",
    "            # чтобы загрузить контент статьи можно вызвать функцию .page\n",
    "            page = load_with_disambigution(page_name)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print('Skipping page {}'.format(page_name), str(e).strip('\\n'))\n",
    "            continue\n",
    "\n",
    "        wiki_content.append(f'{page.title}\\n{page.content.replace(\"==\", \"\")}')\n",
    "\n",
    "    return wiki_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b558aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\scoop\\apps\\python\\current\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Alex\\scoop\\apps\\python\\current\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 10\n",
      "Skipping page Therre \"Therre\" may refer to: \n",
      "Hans Therre\n",
      "Walter Therre\n",
      "Skipping page Friederike Müller \"Friederike Müller\" may refer to: \n",
      "Friederike Müller (Pianistin)\n",
      "Friederike Auguste Müller\n",
      "de 8\n",
      "es 10\n",
      "Skipping page Huta-Złomy HTTPSConnectionPool(host='fr.wikipedia.org', port=443): Max retries exceeded with url: /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Huta-Z%C5%82omy&srinfo=suggestion&format=json&action=query (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001BDE8AEAE10>, 'Connection to fr.wikipedia.org timed out. (connect timeout=None)'))\n",
      "fr 9\n",
      "Skipping page Dornier \"Dornier\" may refer to: \n",
      "Claudius Dornier\n",
      "Claudius Dornier\n",
      "Dornier Flugzeugwerke\n",
      "Dornier Flugzeugwerke\n",
      "DORNIER GmbH\n",
      "Lindauer DORNIER GmbH\n",
      "sl 9\n",
      "CPU times: total: 312 ms\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wiki_texts = {}\n",
    "\n",
    "for lang in langs:\n",
    "    try:\n",
    "        wiki_texts[lang] = get_texts_for_lang(lang, 10)\n",
    "    except Exception as e:\n",
    "        print('ERROR ON - ', lang, str(e).strip('\\n'))\n",
    "        continue\n",
    "    \n",
    "    print(lang, len(wiki_texts[lang]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7734d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Grisebachs Schwertpflanze\\nGrisebachs Schwertpflanze (Echinodorus grisebachii), Synonym: E. bleherae, ist eine Pflanzenart aus der Gattung Schwertpflanzen (Echinodorus) innerhalb der Familie der Froschlöffelgewächse (Alismataceae). Sie wird als Aquarienpflanze verwendet.\\n\\n\\n Beschreibung \\n\\nBei dieser Sumpfpflanze handelt es sich um eine mittel- bis große und kräftig wachsende, ausdauernde krautige Pflanze, die Rhizome ausbildet. Die bandförmigen bis linealischen Laubblätter stehen in einer Blattrosette zusammen. Die Blattoberseite ist mittel- bis dunkelgrün.\\n\\n\\n Taxonomie \\nDie Erstbeschreibung von Echinodorus grisebachii erfolgte 1909 durch John Kunkel Small in Nathaniel Lord Britton & al. (Hrsg.): North American Flora, Volume 17, S 46. Das Artepitheton grisebachii ehrt den deutschen Botaniker August Grisebach. Synonyme für Echinodorus grisebachii Small sind: Echinodorus amphibius Rataj, Echinodorus gracilis Rataj, Echinodorus amazonicus Rataj, Echinodorus bleherae Rataj, Echinodorus parviflorus Rataj (Schwarze Schwertpflanze), Echinodorus eglandulosus Holm-Niels. & R.R.Haynes, Echinodorus grisebachii var. minor Kasselm.\\n\\n\\n Vorkommen \\nDas natürliche neotropische weite Verbreitungsgebiet reicht von Honduras bis Brasilien.\\n\\n\\n Nutzung in der Aquaristik \\nWie einige andere Echinodorus-Arten zählt auch Grisebachs Schwertpflanze zu den beliebten Aquarienpflanzen. Grisebachs Schwertpflanze gilt dabei als anspruchslose Pflanze. Im Zoofachhandel wird sie allerdings nur selten angeboten.\\nIm Aquarium gedeiht Grisebachs Schwertpflanze am besten bei Temperaturen zwischen 22 und 28 Grad Celsius. Sie eignet sich als Mittel- und Hintergrund- sowie als Solitärpflanze. Ideal sind größere Wasserbecken ab etwa 150 Liter und mehr.\\n\\n\\n Literatur \\nHans-Georg Kramer: Pflanzenaquaristik á la Kramer. Tetra-Verlag, Berlin-Velten 2009, ISBN 978-3-89745-190-2, S. 126 f. (Echinodorus parviflorus, Echinodorus peruensis, Schwarze Amazonaspflanze).\\nChristel Kasselmann: Pflanzenaquarien gestalten. Franckh-Kosmos Verlag, Stuttgart 2001, ISBN 3-440-08518-X.\\nChristel Kasselmann: Aquarienpflanzen. Ulmer Verlag, Stuttgart, 2. Auflage. 1999, ISBN 3-8001-7454-5, S. 238, 244, 250 f. und 261 f.\\nJozef Somogyi: Taxonomic, nomenclatural and chorological notes on several taxa of the genus Echinodorus (Alismataceae). Biologia 61 (4): 381–385 (August 2006).\\n\\n\\n= Einzelnachweise ='"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_texts['de'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3f45414",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = punctuation\n",
    "stops+='\\\\n—\\\\t-'\n",
    "def preproc (text):\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    prepr_text = ' '.join([token for token in tokenized if token not in stops])\n",
    "    return prepr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84c2498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_19652\\2889167237.py:16: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  char_set = set(re.findall(\"\\w\", text.lower())) - digits\n"
     ]
    }
   ],
   "source": [
    "preprocessed_wiki = wiki_texts\n",
    "for lang in preprocessed_wiki:\n",
    "    i=0\n",
    "    for text in preprocessed_wiki[lang]:\n",
    "        prep_text = preproc(text)\n",
    "        preprocessed_wiki[lang][i] = prep_text\n",
    "        i+=1\n",
    "\n",
    "digits = set(digits)\n",
    "\n",
    "lang2chars = defaultdict (set)\n",
    "\n",
    "\n",
    "for lang in preprocessed_wiki:\n",
    "    for text in preprocessed_wiki[lang]:\n",
    "        char_set = set(re.findall(\"\\w\", text.lower())) - digits\n",
    "        lang2chars[lang].update(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c04af012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'v', 'b', 'à', 'a']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lang2chars['fr'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4a34b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_19652\\3485445251.py:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  text_chars = set(re.findall('\\w', text.lower())) - digits\n"
     ]
    }
   ],
   "source": [
    "def predict_language(text, lang2char):\n",
    "    text_chars = set(re.findall('\\w', text.lower())) - digits\n",
    "    lang2sim = {}\n",
    "    \n",
    "    for lang in lang2char:\n",
    "        intersect = len(text_chars & lang2char[lang])\n",
    "        lang2sim[lang] = intersect\n",
    "    \n",
    "    return max(lang2sim.items(), key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfbb0436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Grisebachs Schwertpflanze Grisebachs Schwertpflanze Echinodorus grisebachii Synonym E. bleherae ist eine Pflanzenart aus der Gattung Schwertpflanzen Echinodorus innerhalb der Familie der Froschlöffelgewächse Alismataceae Sie wird als Aquarienpflanze verwendet Beschreibung Bei dieser Sumpfpflanze handelt es sich um eine mittel- bis große und kräftig wachsende ausdauernde krautige Pflanze die Rhizome ausbildet Die bandförmigen bis linealischen Laubblätter stehen in einer Blattrosette zusammen Die Blattoberseite ist mittel- bis dunkelgrün Taxonomie Die Erstbeschreibung von Echinodorus grisebachii erfolgte 1909 durch John Kunkel Small in Nathaniel Lord Britton al Hrsg North American Flora Volume 17 S 46 Das Artepitheton grisebachii ehrt den deutschen Botaniker August Grisebach Synonyme für Echinodorus grisebachii Small sind Echinodorus amphibius Rataj Echinodorus gracilis Rataj Echinodorus amazonicus Rataj Echinodorus bleherae Rataj Echinodorus parviflorus Rataj Schwarze Schwertpflanze Echinodorus eglandulosus Holm-Niels R.R.Haynes Echinodorus grisebachii var minor Kasselm Vorkommen Das natürliche neotropische weite Verbreitungsgebiet reicht von Honduras bis Brasilien Nutzung in der Aquaristik Wie einige andere Echinodorus-Arten zählt auch Grisebachs Schwertpflanze zu den beliebten Aquarienpflanzen Grisebachs Schwertpflanze gilt dabei als anspruchslose Pflanze Im Zoofachhandel wird sie allerdings nur selten angeboten Im Aquarium gedeiht Grisebachs Schwertpflanze am besten bei Temperaturen zwischen 22 und 28 Grad Celsius Sie eignet sich als Mittel- und Hintergrund- sowie als Solitärpflanze Ideal sind größere Wasserbecken ab etwa 150 Liter und mehr Literatur Hans-Georg Kramer Pflanzenaquaristik á la Kramer Tetra-Verlag Berlin-Velten 2009 ISBN 978-3-89745-190-2 S. 126 f. Echinodorus parviflorus Echinodorus peruensis Schwarze Amazonaspflanze Christel Kasselmann Pflanzenaquarien gestalten Franckh-Kosmos Verlag Stuttgart 2001 ISBN 3-440-08518-X Christel Kasselmann Aquarienpflanzen Ulmer Verlag Stuttgart 2 Auflage 1999 ISBN 3-8001-7454-5 S. 238 244 250 f. und 261 f. Jozef Somogyi Taxonomic nomenclatural and chorological notes on several taxa of the genus Echinodorus Alismataceae Biologia 61 4 381–385 August 2006 Einzelnachweise'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_texts['de'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1ccd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenized_wiki = wiki_texts\n",
    "for lang in sent_tokenized_wiki:\n",
    "    i=0\n",
    "    for text in sent_tokenized_wiki[lang]:\n",
    "        if lang == 'de':\n",
    "            text = sent_tokenize(text, language='german')\n",
    "        elif lang == 'it':\n",
    "            text = sent_tokenize(text, language='italian')\n",
    "        elif lang == 'fr':\n",
    "            text = sent_tokenize(text, language='french')\n",
    "        elif lang == 'es':\n",
    "            text = sent_tokenize(text, language='spanish')\n",
    "        elif lang == 'sl':\n",
    "            text = sent_tokenize(text, language='slovene')\n",
    "        sent_tokenized_wiki[lang][i] = text\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4b9de92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Grisebachs Schwertpflanze Grisebachs Schwertpflanze Echinodorus grisebachii Synonym E. bleherae ist eine Pflanzenart aus der Gattung Schwertpflanzen Echinodorus innerhalb der Familie der Froschlöffelgewächse Alismataceae Sie wird als Aquarienpflanze verwendet Beschreibung Bei dieser Sumpfpflanze handelt es sich um eine mittel- bis große und kräftig wachsende ausdauernde krautige Pflanze die Rhizome ausbildet Die bandförmigen bis linealischen Laubblätter stehen in einer Blattrosette zusammen Die Blattoberseite ist mittel- bis dunkelgrün Taxonomie Die Erstbeschreibung von Echinodorus grisebachii erfolgte 1909 durch John Kunkel Small in Nathaniel Lord Britton al Hrsg North American Flora Volume 17 S 46 Das Artepitheton grisebachii ehrt den deutschen Botaniker August Grisebach Synonyme für Echinodorus grisebachii Small sind Echinodorus amphibius Rataj Echinodorus gracilis Rataj Echinodorus amazonicus Rataj Echinodorus bleherae Rataj Echinodorus parviflorus Rataj Schwarze Schwertpflanze Echinodorus eglandulosus Holm-Niels R.R.Haynes Echinodorus grisebachii var minor Kasselm Vorkommen Das natürliche neotropische weite Verbreitungsgebiet reicht von Honduras bis Brasilien Nutzung in der Aquaristik Wie einige andere Echinodorus-Arten zählt auch Grisebachs Schwertpflanze zu den beliebten Aquarienpflanzen Grisebachs Schwertpflanze gilt dabei als anspruchslose Pflanze Im Zoofachhandel wird sie allerdings nur selten angeboten Im Aquarium gedeiht Grisebachs Schwertpflanze am besten bei Temperaturen zwischen 22 und 28 Grad Celsius Sie eignet sich als Mittel- und Hintergrund- sowie als Solitärpflanze Ideal sind größere Wasserbecken ab etwa 150 Liter und mehr Literatur Hans-Georg Kramer Pflanzenaquaristik á la Kramer Tetra-Verlag Berlin-Velten 2009 ISBN 978-3-89745-190-2 S. 126 f. Echinodorus parviflorus Echinodorus peruensis Schwarze Amazonaspflanze Christel Kasselmann Pflanzenaquarien gestalten Franckh-Kosmos Verlag Stuttgart 2001 ISBN 3-440-08518-X Christel Kasselmann Aquarienpflanzen Ulmer Verlag Stuttgart 2 Auflage 1999 ISBN 3-8001-7454-5 S. 238 244 250 f. und 261 f. Jozef Somogyi Taxonomic nomenclatural and chorological notes on several taxa of the genus Echinodorus Alismataceae Biologia 61 4 381–385 August 2006 Einzelnachweise']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenized_wiki['de'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26da5829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             sentence language  id\n",
      "0   [Yasmin Finney Yasmin Finney Manchester 30 ago...       it   1\n",
      "1   [Zorro Zorro Volpe in lingua spagnola è un per...       it   1\n",
      "2   [Erik Heijblok Erik Heijblok Den Oever 29 giug...       it   1\n",
      "3   [Ghost Town film 2008 Ghost Town trad lett Cit...       it   1\n",
      "4   [Kurts Plade Kurts Plade Riga 16 agosto 1898 –...       it   1\n",
      "5   [Jesmond Delia Jesmond Delia 20 marzo 1967 è u...       it   1\n",
      "6   [Iuri Capelo Iuri Kaewchang Capelo Macao 27 ot...       it   1\n",
      "7   [One More Time Rod Stewart One More Time è un ...       it   1\n",
      "8   [Roy Dotrice Roy Dotrice Guernsey 26 maggio 19...       it   1\n",
      "9   [Società Autostrade Alto Adriatico Società Aut...       it   1\n",
      "10  [Pierre Bernard Milius Pierre Bernard Milius 4...       de   2\n",
      "11  [Liste der Gewässer namens Aa Aa im Alpenraum ...       de   2\n",
      "12  [Grisebachs Schwertpflanze Grisebachs Schwertp...       de   2\n",
      "13  [Franz Erasmus Spannheimer Franz Erasmus Spann...       de   2\n",
      "14  [Tupolew-Tu-204/214-Familie Die Tupolew Tu-204...       de   2\n",
      "15  [Australische Unihockeynationalmannschaft der ...       de   2\n",
      "16  [CAdES CAdES CMS Advanced Electronic Signature...       de   2\n",
      "17  [Komma Verslehre Ein Komma Plural Kommata altg...       de   2\n",
      "18  [Fabiola León-Velarde Fabiola León-Velarde Ser...       es   3\n",
      "19  [Orden ejecutiva 9066 La Orden Ejecutiva 9066 ...       es   3\n",
      "20  [Renault RE40 El Renault RE40 es un monoplaza ...       es   3\n",
      "21  [Estación de Fairhaven Fairhaven también llama...       es   3\n",
      "22  [Escudo de armas del estado Carabobo El escudo...       es   3\n",
      "23  [Cotorrillo Cotorrillo es un despoblado españo...       es   3\n",
      "24  [Kiríkivka Kiríkivka en ucraniano Кириківка ro...       es   3\n",
      "25  [Felipe Contepomi Felipe Contepomi Buenos Aire...       es   3\n",
      "26  [Aulacoderus trilobatus Aulacoderus trilobatus...       es   3\n",
      "27  [Henri Gervais Henri Frédéric Paul Gervais nac...       es   3\n",
      "28  [Maison-musée de Mammed Said Ordubadi Bakou La...       fr   4\n",
      "29  [Fossiles de Bitter Springs Le gisement fossil...       fr   4\n",
      "30  [Liolaemus canqueli Liolaemus canqueli est une...       fr   4\n",
      "31  [Pollyanna film 1960 Pollyanna est un film amé...       fr   4\n",
      "32  [Killearn Killearn est un village dans le Stir...       fr   4\n",
      "33  [Erecinae Les Erecinae sont une sous-famille d...       fr   4\n",
      "34  [John Choyce John Choyce né le 28 novembre 193...       fr   4\n",
      "35  [Robert Ier de Hesbaye Robert Ier de Hesbaye R...       fr   4\n",
      "36  [Louis-Joseph Alcide Railliet Louis Joseph Alc...       fr   4\n",
      "37  [AN-94 AN-94 Abakan je moderna ruska jurišna p...       sl   5\n",
      "38  [HMS Picotee K63 HMS Picotee K63 je bila korve...       sl   5\n",
      "39  [Gornje Laze Górnje Láze je naselje v Slovenij...       sl   5\n",
      "40  [Abraham van Beijeren Abraham van Beijeren niz...       sl   5\n",
      "41  [Dove Dove je priimek več znanih oseb Alfred D...       sl   5\n",
      "42  [Kanonloppet 1963 Kanonloppet 1963 je bila des...       sl   5\n",
      "43  [Likovič Likovič je priimek več znanih Slovenc...       sl   5\n",
      "44  [Javni intelektualec Javni intelektualec je es...       sl   5\n",
      "45  [Nuovo Cimento Nuovo Cimento je niz fizikalnih...       sl   5\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "i=1\n",
    "for lang in wiki_texts:\n",
    "    for text in wiki_texts[lang]:\n",
    "        l_id = i\n",
    "        data.append((text, lang, l_id))\n",
    "    i+=1\n",
    "\n",
    "df = pd.DataFrame (data, columns=['sentence','language', 'id'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50049252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\scoop\\apps\\python\\current\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\Alex\\scoop\\apps\\python\\current\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embed = model.encode\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "425b6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('language')[['sentence', 'language', 'id']]\n",
    "ARI = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b02d9733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2376237623762376\n"
     ]
    }
   ],
   "source": [
    "sentences = df['sentence'].values\n",
    "\n",
    "texts = list()\n",
    "\n",
    "for sent in sentences:\n",
    "    texts.extend(sent)\n",
    "\n",
    "X = np.zeros((len(texts), 768))\n",
    "for i, txt in enumerate(texts):\n",
    "    X[i] = embed(txt)\n",
    "\n",
    "cluster = AffinityPropagation(damping=0.5)\n",
    "    \n",
    "cluster.fit(X)\n",
    "labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "sents = list()\n",
    "true_labels = list()\n",
    "\n",
    "for id_, sentence_list in zip(df[\"id\"].values, df[\"sentence\"].values):\n",
    "\n",
    "    sents.extend(sentence_list)\n",
    "    true_labels.extend([id_]*len(sentence_list))\n",
    "\n",
    "ARI.append(adjusted_rand_score(true_labels, labels))\n",
    "    \n",
    "print(np.mean(ARI)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd75839",
   "metadata": {},
   "source": [
    "# Задание 2\n",
    "\n",
    "Загрузите корпус `annot.opcorpora.no_ambig_strict.xml.bz2` с OpenCorpora. Найдите в корпусе самые частотные морфологически омонимичные словоформы (те, которым соответствует разный грамматический разбор в разных предложениях). Также найдите словоформы с самых большим количеством вариантов грамматических разборов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdbe942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "from lxml import etree\n",
    "\n",
    "with bz2.open('annot.opcorpora.no_ambig_strict.xml.bz2', 'rb') as f_in, open('annot.opcorpora.no_ambig_strict.xml', 'wb') as f_out:\n",
    "    f_out.write(f_in.read())\n",
    "\n",
    "open_corpora = etree.fromstring(open('annot.opcorpora.no_ambig_strict.xml', 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ed11ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = open_corpora.xpath('//tokens')\n",
    "tokens = sentences[0].xpath('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be265156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['«', 'PNCT'], ['Школа', 'NOUN', 'inan', 'femn', 'sing', 'nomn'], ['злословия', 'NOUN', 'inan', 'neut', 'sing', 'gent'], ['»', 'PNCT'], ['учит', 'VERB', 'impf', 'tran', 'sing', '3per', 'pres', 'indc'], ['прикусить', 'INFN', 'perf', 'tran'], ['язык', 'NOUN', 'inan', 'masc', 'sing', 'accs']], [['Сохранится', 'VERB', 'perf', 'intr', 'sing', '3per', 'futr', 'indc'], ['ли', 'PRCL'], ['градус', 'NOUN', 'inan', 'masc', 'sing', 'nomn'], ['дискуссии', 'NOUN', 'inan', 'femn', 'sing', 'gent'], ['в', 'PREP'], ['новом', 'ADJF', 'Qual', 'masc', 'sing', 'loct'], ['сезоне', 'NOUN', 'inan', 'masc', 'sing', 'loct'], ['?', 'PNCT']], [['Великолепная', 'ADJF', 'Qual', 'femn', 'sing', 'nomn'], ['«', 'PNCT'], ['Школа', 'NOUN', 'inan', 'femn', 'sing', 'nomn'], ['злословия', 'NOUN', 'inan', 'neut', 'sing', 'gent'], ['»', 'PNCT'], ['вернулась', 'VERB', 'perf', 'intr', 'femn', 'sing', 'past', 'indc'], ['в', 'PREP'], ['эфир', 'NOUN', 'inan', 'masc', 'sing', 'accs'], ['после', 'PREP'], ['летних', 'ADJF', 'plur', 'gent'], ['каникул', 'NOUN', 'inan', 'GNdr', 'Pltm', 'plur', 'gent'], ['в', 'PREP'], ['новом', 'ADJF', 'Qual', 'masc', 'sing', 'loct'], ['формате', 'NOUN', 'inan', 'masc', 'sing', 'loct'], ['.', 'PNCT']], [['Потом', 'ADVB'], ['проект', 'NOUN', 'inan', 'masc', 'sing', 'nomn'], ['переехал', 'VERB', 'perf', 'tran', 'masc', 'sing', 'past', 'indc'], ['с', 'PREP'], ['«', 'PNCT'], ['Культуры', 'NOUN', 'inan', 'femn', 'sing', 'gent'], ['»', 'PNCT'], ['на', 'PREP'], ['НТВ', 'NOUN', 'inan', 'neut', 'Sgtm', 'Fixd', 'Abbr', 'Orgn', 'sing', 'accs'], ['.', 'PNCT']], [['Это', 'NPRO', 'neut', 'sing', 'nomn'], ['помимо', 'PREP'], ['явных', 'ADJF', 'Qual', 'plur', 'gent'], ['перемен', 'NOUN', 'inan', 'femn', 'plur', 'gent'], ['в', 'PREP'], ['виде', 'NOUN', 'inan', 'masc', 'sing', 'loc1'], ['тут', 'ADVB', 'Dmns'], ['же', 'PRCL'], ['появившихся', 'PRTF', 'perf', 'intr', 'past', 'actv', 'plur', 'gent'], ['рекламных', 'ADJF', 'Qual', 'plur', 'gent'], ['блоков', 'NOUN', 'inan', 'masc', 'plur', 'gent'], [',', 'PNCT'], ['отсутствовавших', 'PRTF', 'impf', 'intr', 'past', 'actv', 'plur', 'gent'], ['на', 'PREP'], ['«', 'PNCT'], ['Культуре', 'NOUN', 'inan', 'femn', 'sing', 'loct'], ['»', 'PNCT'], [',', 'PNCT'], ['позволило', 'VERB', 'perf', 'tran', 'neut', 'sing', 'past', 'indc'], [',', 'PNCT'], ['с', 'PREP'], ['одной', 'ADJF', 'Apro', 'Anum', 'femn', 'sing', 'gent'], ['стороны', 'NOUN', 'inan', 'femn', 'sing', 'gent'], [',', 'PNCT'], ['расширить', 'INFN', 'perf', 'tran'], ['круг', 'NOUN', 'inan', 'masc', 'sing', 'accs'], ['гостей', 'NOUN', 'anim', 'masc', 'plur', 'gent'], [',', 'PNCT'], ['с', 'PREP'], ['другой', 'ADJF', 'Apro', 'Subx', 'femn', 'sing', 'gent'], ['–', 'PNCT'], ['изменить', 'INFN', 'perf', 'tran'], ['тон', 'NOUN', 'inan', 'masc', 'sing', 'accs'], ['разговора', 'NOUN', 'inan', 'masc', 'sing', 'gent'], ['.', 'PNCT']], [['Народные', 'ADJF', 'Qual', 'plur', 'nomn'], ['любимцы', 'NOUN', 'anim', 'masc', 'plur', 'nomn']], [['Продлится', 'VERB', 'perf', 'intr', 'sing', '3per', 'futr', 'indc'], ['она', 'NPRO', 'femn', '3per', 'Anph', 'sing', 'nomn'], ['55', 'NUMB'], ['дней', 'NOUN', 'inan', 'masc', 'plur', 'gent'], [',', 'PNCT'], ['до', 'PREP'], ['5', 'NUMB'], ['ноября', 'NOUN', 'inan', 'masc', 'sing', 'gent'], ['.', 'PNCT']], [['За', 'PREP'], ['кота', 'NOUN', 'anim', 'masc', 'sing', 'accs'], ['–', 'PNCT'], ['ответишь', 'VERB', 'perf', 'intr', 'sing', '2per', 'futr', 'indc'], ['!', 'PNCT']], [['Шпаги', 'NOUN', 'inan', 'femn', 'plur', 'nomn'], [',', 'PNCT'], ['деньги', 'NOUN', 'inan', 'femn', 'plur', 'nomn'], [',', 'PNCT'], ['биржа', 'NOUN', 'inan', 'femn', 'sing', 'nomn']], [['Звери', 'NOUN', 'anim', 'masc', 'plur', 'nomn'], [',', 'PNCT'], ['деньги', 'NOUN', 'inan', 'femn', 'plur', 'nomn'], [',', 'PNCT'], ['наркота', 'NOUN', 'inan', 'femn', 'Sgtm', 'sing', 'nomn']]]\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "\n",
    "for sentence in open_corpora.xpath('//tokens'):\n",
    "    sent_tagged = []\n",
    "    for token in sentence.xpath('token'):\n",
    "        word = token.xpath('@text')\n",
    "        gram_info = token.xpath('tfr/v/l/g/@v')\n",
    "        sent_tagged.append([word[0]] + gram_info)\n",
    "    \n",
    "    corpus.append(sent_tagged)\n",
    "\n",
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d967d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_items = []\n",
    "corp : dict[str, set[str]] = dict()\n",
    "\n",
    "for line in corpus:\n",
    "    for word in line:\n",
    "        name = word[0]\n",
    "        gram = str(word[1:])\n",
    "        if name not in corp_items:\n",
    "            corp[name] = {gram}\n",
    "            corp_items.append(name)\n",
    "        else:\n",
    "            corp[name].add(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9ed99da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"['NOUN', 'inan', 'GNdr', 'Pltm', 'Fixd', 'Abbr', 'Geox', 'plur', 'ablt']\", \"['NOUN', 'inan', 'GNdr', 'Pltm', 'Fixd', 'Abbr', 'Geox', 'plur', 'loct']\", \"['NOUN', 'inan', 'GNdr', 'Pltm', 'Fixd', 'Abbr', 'Geox', 'plur', 'accs']\", \"['NOUN', 'inan', 'GNdr', 'Pltm', 'Fixd', 'Abbr', 'Geox', 'plur', 'nomn']\", \"['NOUN', 'inan', 'GNdr', 'Pltm', 'Fixd', 'Abbr', 'Geox', 'plur', 'gent']\", \"['NOUN', 'inan', 'GNdr', 'Pltm', 'Fixd', 'Abbr', 'Geox', 'plur', 'datv']\"}\n"
     ]
    }
   ],
   "source": [
    "print (corp['США'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ed27b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ded690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_most_items = []\n",
    "\n",
    "for line in corpus:\n",
    "    for word in line:\n",
    "        name = word[0]\n",
    "        corp_most_items.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1444137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в', 1583), ('на', 686), ('с', 536), ('и', 507), ('году', 115)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_omonims = Counter()\n",
    "\n",
    "for word, gram in corp.items():\n",
    "    if len(gram)>1:\n",
    "        num_words = corp_most_items.count(word)\n",
    "        counter_omonims[word] = num_words\n",
    "\n",
    "counter_omonims.most_common(5) #самые частотные морфологически омонимичные словоформы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e055ab7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('США', 6), ('кино', 5), ('евро', 5), ('компании', 5), ('какой', 5)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_longest = Counter()\n",
    "\n",
    "for word, gram in corp.items():\n",
    "    if len(gram)>1:\n",
    "        counter_longest[word] = len(gram)\n",
    "\n",
    "counter_longest.most_common(5) #словоформы с самым большим количеством вариантов грам. разбора"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b29c9c",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "Загрузите один и з файлов корпуса Syntagrus - https://github.com/UniversalDependencies/UD_Russian-SynTagRus/tree/master (можно взять тестовый)\n",
    "\n",
    "Преобразуйте все разборы предложений в графовые структуры через DependencyGraph, выберите 3 любых отношения и для каждого найдите топ-5 самых встречаемых пар слов, связанных этим отношением. \n",
    "\n",
    "Для самой частотной пары слов в каждом из отношений вытащите все подзависимые слова для каждого из них во всех предложениях (используя `flatten(get_subtree(d.nodes, index_of_a_word)` и сортируя результат по порядку слов в предложениях, аналогично тому как я делал с summaries только у вас будет два слова) \n",
    "В итоге у вас должен получится что-то такое:\n",
    "\n",
    "```\n",
    "### отношение\n",
    "relation_name\n",
    "\n",
    "### топ 5 пар слов связанных этим отношением\n",
    "(word1, word2), (word3, word4), (word5, word6), (word7, word8), (word9, word10)\n",
    "\n",
    "### подзависимые для самого частотного\n",
    "(subword word1 subword, word2 subword subword)\n",
    "\n",
    "... (и так три раза)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04e97613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import DependencyGraph\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28ab1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('ru_syntagrus-ud-train-b.conllu', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fedea07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = []\n",
    "parsed_sents = [sentence.split(\"\\n\") for sentence in file.split('\\n\\n')]\n",
    "for sentence in parsed_sents:\n",
    "    tree = [x.replace(\"\\t\", \" \") for x in sentence if not x.startswith(\"#\")]\n",
    "    trees.append('\\n'.join(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddd660bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(l):\n",
    "    result = []\n",
    "    \n",
    "    for el in l:\n",
    "        # окончание рекурсии - если текущий элемент не список\n",
    "        if not isinstance(el, list):\n",
    "            result.append(el)\n",
    "        #если текущий элемент список, то применяем к нему flatten_list \n",
    "        else:\n",
    "            result += flatten_list(el)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_subtree(nodes, node):\n",
    "    \n",
    "    \n",
    "    if not nodes[node]['deps']:\n",
    "        return [node]\n",
    "    \n",
    "    else:\n",
    "        return [node] + [get_subtree(nodes, dep) for rel in nodes[node]['deps'] \n",
    "                         if rel != 'punct'\n",
    "                         for dep in nodes[node]['deps'][rel]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd37f319",
   "metadata": {},
   "source": [
    "Отношение 'NOUN' - 'appos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22d1015e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('тетя', 'Шура'), 12),\n",
       " (('президент', 'Владимир'), 10),\n",
       " (('г-н', 'Путин'), 8),\n",
       " (('провинции', 'Пактия'), 8),\n",
       " (('движения', 'Талибан'), 6)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_appos = Counter()\n",
    "\n",
    "AAA = []  #сюда пойдут битые предложения, потому что DependencyGraph их почему-то не воспринимает :(\n",
    "\n",
    "for tree in trees:\n",
    "    try:\n",
    "        d = DependencyGraph(tree)\n",
    "        d.root = d.nodes[0] \n",
    "        triples = list(d.triples())\n",
    "        for e1, rel, e2 in triples:\n",
    "            if e1[1] == 'NOUN' and rel == 'appos':\n",
    "                pairs_appos[e1[0], e2[0]]+=1\n",
    "    except Exception:\n",
    "        AAA.append(tree)\n",
    "        pass\n",
    "counter_appos = Counter(pairs_appos)\n",
    "counter_appos.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aff4f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_appos, w2_appos = counter_appos.most_common(1)[0][0]\n",
    "subtrees_for_appos1 = list()\n",
    "subtrees_for_appos2 = list()\n",
    "for tree in trees:\n",
    "    try:\n",
    "        d = DependencyGraph(tree)\n",
    "        d.root = d.nodes[0] \n",
    "        for i, node in d.nodes.items():\n",
    "            if node['word'] == w1_appos:\n",
    "                index1_appos = i\n",
    "                appos1 = (sorted(flatten_list(get_subtree(d.nodes, index1_appos))))\n",
    "                for j in appos1:\n",
    "                    subtrees_for_appos1.append(d.nodes[j]['word'])\n",
    "            elif node['word'] == w2_appos:\n",
    "                index2_appos = i\n",
    "                appos2 = (sorted(flatten_list(get_subtree(d.nodes, index2_appos))))\n",
    "                for j in appos2: \n",
    "                    subtrees_for_appos2.append(d.nodes[j]['word'])\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcebead1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип отношений - appos\n",
      "Топ 5 пар слов связанных этим отношением:  [(('тетя', 'Шура'), 12), (('президент', 'Владимир'), 10), (('г-н', 'Путин'), 8), (('провинции', 'Пактия'), 8), (('движения', 'Талибан'), 6)]\n",
      "Подзависимые для самого частотного:\n",
      " тетя  -  ['ее', 'тетя', 'у', 'которой', 'она', 'жила', 'Ее', 'тетя', 'вдова', 'священника', 'Шурочкина', 'тетя', 'моя', 'любимая', 'тетя', 'Клава', 'тетя', 'тетя', 'Вера', 'и'] \n",
      " Шура  -  ['Шура', 'Шура', 'Шура', 'Шура', 'Шура', 'Шура', 'управдомша', 'Шура', 'Шура', 'управдомша', 'Шура', 'Шура', 'управдомша', 'Шура', 'Шура', 'управдомша', 'Шура', 'Шура', 'Шура', 'Шура']\n"
     ]
    }
   ],
   "source": [
    "print('Тип отношений - appos')\n",
    "print('Топ 5 пар слов связанных этим отношением: ', counter_appos.most_common(5))\n",
    "print('Подзависимые для самого частотного:\\n',w1_appos, ' - ', subtrees_for_appos1[:20], '\\n', w2_appos, ' - ', subtrees_for_appos2[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3461040b",
   "metadata": {},
   "source": [
    "NOUN - 'case'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19160a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('в', 'году'), 269),\n",
       " (('в', 'случае'), 132),\n",
       " (('По', 'словам'), 121),\n",
       " (('в', 'время'), 117),\n",
       " (('в', 'числе'), 96)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_case = Counter()\n",
    "\n",
    "for tree in trees:\n",
    "    try:\n",
    "        d = DependencyGraph(tree)\n",
    "        d.root = d.nodes[0] \n",
    "        triples = list(d.triples())\n",
    "        for e1, rel, e2 in triples:\n",
    "            if e1[1] == 'NOUN' and rel=='case':\n",
    "                 pairs_case[e2[0], e1[0]]+=1\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "counter_case = Counter(pairs_case)\n",
    "counter_case.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75d75338",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_case, w2_case = counter_case.most_common(1)[0][0]\n",
    "subtrees_for_case1 = list()\n",
    "subtrees_for_case2 = list()\n",
    "for tree in trees:\n",
    "    try:\n",
    "        d = DependencyGraph(tree)\n",
    "        d.root = d.nodes[0] \n",
    "        for i, node in d.nodes.items():\n",
    "            if node['word'] == w1_case:\n",
    "                index1_case = i\n",
    "                case1 = (sorted(flatten_list(get_subtree(d.nodes, index1_case))))\n",
    "                for j in case1:\n",
    "                    subtrees_for_case1.append(d.nodes[j]['word'])\n",
    "            elif node['word'] == w2_case:\n",
    "                index2_case = i\n",
    "                case2 = (sorted(flatten_list(get_subtree(d.nodes, index2_case))))\n",
    "                for j in case2: \n",
    "                    subtrees_for_case2.append(d.nodes[j]['word'])\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79dc120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип отношений - case\n",
      "Топ 5 пар слов связанных этим отношением:  [(('в', 'году'), 269), (('в', 'случае'), 132), (('По', 'словам'), 121), (('в', 'время'), 117), (('в', 'числе'), 96)]\n",
      "Подзависимые для самого частотного:\n",
      " в  -  ['в', 'в', 'в', 'в', 'в', 'в', 'в', 'в', 'в', 'частности', 'в', 'в', 'в', 'в', 'связи', 'с', 'в', 'в', 'в', 'в'] \n",
      " году  -  ['В', '2007', '2008', 'учебном', 'году', 'В', 'этом', 'году', 'В', 'этом', 'году', 'В', '2008', 'году', 'в', 'прошлом', 'году', 'уже', 'в', 'этом']\n"
     ]
    }
   ],
   "source": [
    "print('Тип отношений - case')\n",
    "print('Топ 5 пар слов связанных этим отношением: ', counter_case.most_common(5))\n",
    "print('Подзависимые для самого частотного:\\n',w1_case, ' - ', subtrees_for_case1[:20], '\\n', w2_case, ' - ', subtrees_for_case2[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f389c21",
   "metadata": {},
   "source": [
    "NOUN - 'nmod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "833a8f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('начале', 'века'), 26),\n",
       " (('корреспондент', 'РИА'), 23),\n",
       " (('президента', 'России'), 17),\n",
       " (('правам', 'человека'), 12),\n",
       " (('зависимости', 'того'), 11)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_nmod = Counter()\n",
    "\n",
    "for tree in trees:\n",
    "    try:\n",
    "        d = DependencyGraph(tree)\n",
    "        d.root = d.nodes[0] \n",
    "        triples = list(d.triples())\n",
    "        for e1, rel, e2 in triples:\n",
    "            if e1[1] == 'NOUN' and rel=='nmod':\n",
    "                 pairs_nmod[e1[0], e2[0]]+=1\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "counter_nmod = Counter(pairs_nmod)\n",
    "counter_nmod.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7578aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_nmod, w2_nmod = counter_nmod.most_common(1)[0][0]\n",
    "subtrees_for_nmod1 = list()\n",
    "subtrees_for_nmod2 = list()\n",
    "for tree in trees:\n",
    "    try:\n",
    "        d = DependencyGraph(tree)\n",
    "        d.root = d.nodes[0] \n",
    "        for i, node in d.nodes.items():\n",
    "            if node['word'] == w1_nmod:\n",
    "                index1_nmod = i\n",
    "                nmod1 = (sorted(flatten_list(get_subtree(d.nodes, index1_nmod))))\n",
    "                for j in nmod1:\n",
    "                    subtrees_for_nmod1.append(d.nodes[j]['word'])\n",
    "            elif node['word'] == w2_nmod:\n",
    "                index2_nmod = i\n",
    "                nmod2 = (sorted(flatten_list(get_subtree(d.nodes, index2_nmod))))\n",
    "                for j in nmod2: \n",
    "                    subtrees_for_nmod2.append(d.nodes[j]['word'])\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2387519b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип отношений - nmod\n",
      "Топ 5 пар слов связанных этим отношением:  [(('начале', 'века'), 26), (('корреспондент', 'РИА'), 23), (('президента', 'России'), 17), (('правам', 'человека'), 12), (('зависимости', 'того'), 11)]\n",
      "Подзависимые для самого частотного:\n",
      " начале  -  ['в', 'начале', '90-х', 'годов', 'прошлого', 'века', 'в', 'начале', 'прошлого', 'года', 'в', 'начале', '2000-х', 'в', 'начале', 'следующего', 'В', 'начале', '2000-х', 'В'] \n",
      " века  -  ['прошлого', 'века', 'почти', 'два', 'века', 'и', 'исторические', 'пробы', 'и', 'ошибки', 'якобинский', 'террор', 'реставрация', 'монархии', 'две', 'империи', 'и', 'множество', 'попыток', 'установления']\n"
     ]
    }
   ],
   "source": [
    "print('Тип отношений - nmod')\n",
    "print('Топ 5 пар слов связанных этим отношением: ', counter_nmod.most_common(5))\n",
    "print('Подзависимые для самого частотного:\\n',w1_nmod, ' - ', subtrees_for_nmod1[:20], '\\n', w2_nmod, ' - ', subtrees_for_nmod2[:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
