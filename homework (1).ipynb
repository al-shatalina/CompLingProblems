{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier as T\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.naive_bayes import MultinomialNB as bayes\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from razdel import tokenize as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbaca07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def razdel_tokenizer(text):\n",
    "    return [token.text for token in list(rt(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6873e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87804ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\scoop\\apps\\python\\3.12.6\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['!', '!!', '!!!', ..., 'ёмкостью', 'ёта', 'ётавских'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1 = TfidfVectorizer (tokenizer = razdel_tokenizer)\n",
    "X1 = vectorizer1.fit_transform(train.comment)\n",
    "X1_test = vectorizer1.transform(test.comment)\n",
    "vectorizer1.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fad348ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0015', ..., 'ёмкостью', 'ёта', 'ётавских'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2 = TfidfVectorizer () #tokenizer = default\n",
    "X2 = vectorizer2.fit_transform(train.comment)\n",
    "X2_test = vectorizer2.transform(test.comment)\n",
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b56a2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = train.toxic.values\n",
    "y1_test = test.toxic.values\n",
    "y2 = train.toxic.values\n",
    "y2_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d27b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.88      0.86       962\n",
      "         1.0       0.74      0.65      0.69       480\n",
      "\n",
      "    accuracy                           0.81      1442\n",
      "   macro avg       0.79      0.77      0.78      1442\n",
      "weighted avg       0.80      0.81      0.80      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RFC(min_samples_leaf = 2, class_weight = 'balanced')\n",
    "clf.fit(X1, y1)\n",
    "preds1 = clf.predict(X1_test)\n",
    "print(classification_report(y1_test, preds1, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff15dc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.88      0.85       962\n",
      "         1.0       0.73      0.63      0.67       480\n",
      "\n",
      "    accuracy                           0.80      1442\n",
      "   macro avg       0.78      0.76      0.76      1442\n",
      "weighted avg       0.79      0.80      0.79      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RFC(min_samples_leaf = 2, class_weight = 'balanced')\n",
    "clf.fit(X2, y2)\n",
    "preds2 = clf.predict(X2_test)\n",
    "print(classification_report(y2_test, preds2, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3941d33",
   "metadata": {},
   "source": [
    "Встроенный токенизатор побеждает"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d62b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0a5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerL = TfidfVectorizer (min_df=4, max_df=0.1, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
    "X_for_L = vectorizerL.fit_transform(train.comment)\n",
    "X_for_L_test = vectorizerL.transform(test.comment)\n",
    "#vectorizerTF.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "745bd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerB = CountVectorizer (min_df=4, max_df=0.3, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
    "X_for_B = vectorizerB.fit_transform(train.comment)\n",
    "X_for_B_test = vectorizerB.transform(test.comment)\n",
    "#vectorizerC.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f4f3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "yL = train.toxic.values\n",
    "yL_test = test.toxic.values\n",
    "yB = train.toxic.values\n",
    "yB_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90311fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89       962\n",
      "         1.0       0.78      0.79      0.78       480\n",
      "\n",
      "    accuracy                           0.85      1442\n",
      "   macro avg       0.83      0.84      0.84      1442\n",
      "weighted avg       0.85      0.85      0.85      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfL = LogisticRegression(penalty='l2', class_weight= 'balanced')\n",
    "clfL.fit(X_for_L, yL)\n",
    "predsL = clfL.predict(X_for_L_test)\n",
    "print(classification_report(yL_test, predsL, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "458e2c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.93      0.89       962\n",
      "         1.0       0.82      0.68      0.74       480\n",
      "\n",
      "    accuracy                           0.84      1442\n",
      "   macro avg       0.84      0.80      0.81      1442\n",
      "weighted avg       0.84      0.84      0.84      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfB = bayes(alpha=1, force_alpha=True)\n",
    "clfB.fit(X_for_B, yB)\n",
    "predsB = clfB.predict(X_for_B_test)\n",
    "print(classification_report(yB_test, predsB, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69608f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "predsB_proba = clfB.predict_proba(X_for_B_test)\n",
    "predsL_proba = clfL.predict_proba(X_for_L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bfad587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b4ccc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ок. Раз уж крахоборничать то пусть будет максимум не - 1 Бар, а - 1,013 '\n",
      "  'Бар. При полной откачке, скажем, воздуха из емкости, на емкость будет '\n",
      "  'воздействовать атмосферное давление, и большее разрежение, чем оно давит, '\n",
      "  'ваккумметр не покажет. То есть максимум - 1 атмосфера, или 1,013 Бар.\\n',\n",
      "  np.float64(1.0)),\n",
      " ('Тиньков! СУКА! Ты по что кредита мне не даешь?! Впрочем...не больно то и '\n",
      "  'хотелось! ....))))',\n",
      "  np.float64(1.0)),\n",
      " ('во-во. побочки в одиссее явно подтянули. намного интереснее проходить и так '\n",
      "  'остро уже этот гринд не ощущается.',\n",
      "  np.float64(1.0)),\n",
      " ('Барином хорошо было быть, в 17-ом веке. Учи себе французкий. Читай книжки. '\n",
      "  'Не жизнь - малина.)',\n",
      "  np.float64(1.0)),\n",
      " ('Бате недавно ставили, многим уже в 40 нужно. А если не повезло с зубами, то '\n",
      "  'и того раньше. Надеюсь, вам повезло :р',\n",
      "  np.float64(0.99999999999892)),\n",
      " ('Как по мне, салденс какую-то хуйню(разумеется, все это 10из10 по сравнению '\n",
      "  'с массмаркетом) начал варить. Десятки сортов, но нету изюминки. Очень мало, '\n",
      "  'из того что запомнилось.',\n",
      "  np.float64(0.999999999991644)),\n",
      " ('Позвольте узнать, скольких детей вы воспитали, дабы утверждать, что ребенок '\n",
      "  '- это примитивный и легко предсказуемый алгоритм, в котором нельзя - значит '\n",
      "  'нельзя? Удобно все и всегда на воспитание спихивать, вроде я ничего в жизни '\n",
      "  'не добился, но не потому что я нихера делать не хочу, а потому что меня так '\n",
      "  'воспитали, моей вины в этом вообще нет. И родители не виноваты, их тоже так '\n",
      "  'воспитали. Адам с Евой всю ответственность несут, а мы так, по течению '\n",
      "  'плывем. Значит люди, которые имеют проблемы с алкоголем - быдло. Люди, дети '\n",
      "  'которых причинили любой вред чужой собственности - быдло. Но может тогда и '\n",
      "  'люди, которые перестают следить за своим здоровьем и мало двигаются - '\n",
      "  'быдло, ведь они тоже осознают риски? Люди, которые вместо саморазвития '\n",
      "  'приходят домой и смотрят сериальчики, просто потому что им лень что-то '\n",
      "  'делать еще, они тоже быдло, ведь разница с алкоголиками в способе '\n",
      "  'отдохнуть, структурно никакой разницы? Но тогда логичный вопрос, а есть ли '\n",
      "  'НЕ быдло на нашей планете?\\n',\n",
      "  np.float64(0.9999999999783427)),\n",
      " ('вот бы столько и правда прожить...', np.float64(0.9999999999346869)),\n",
      " ('(- - ) Ты не модер чтоб, клубничку пропускать...\\n',\n",
      "  np.float64(0.9999999998289013)),\n",
      " ('Впервые докопался , а надо было ждать второго-третьего раза, что бы '\n",
      "  'поставить утырка на место? А может ты и сам был таким утырком в школе, и '\n",
      "  'тебе обидно, что тебя какой-то новенький поставил на место?\\n',\n",
      "  np.float64(0.9999999965720008))]\n"
     ]
    }
   ],
   "source": [
    "counterB = Counter({comm: prob[1] for comm, prob in zip(data.comment, predsB_proba)})\n",
    "B_fin = counterB.most_common(10)\n",
    "pprint(B_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f433ecce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Переведите этот поток сознания хотя бы хохляцкий, плиз.\\n',\n",
      "  np.float64(0.9885916374155893)),\n",
      " ('Я бы на месте цыганки выбил бы телефон из рук и лицо бы поцарапал,за это '\n",
      "  'ничего не будет,просто административный штраф,а пикабушник запомнит,что '\n",
      "  'дерьмом по жизни быть нельзя и судить других никто не имеет права.\\n',\n",
      "  np.float64(0.9840106318453373)),\n",
      " ('я вот не пойму, я у тебя совета что-ли из раза в раз прошу?\\n',\n",
      "  np.float64(0.9777982005413092)),\n",
      " ('Так там по сути никто и не работает дольше 3-х лет для стажа в типа сириус '\n",
      "  'конторе. У нас в филиале роскосого так: после универа за 15-20к работают во '\n",
      "  'всяких лабораториях, потом уебывают на вольные хлеба. Постоянно там только '\n",
      "  'старичье совкового пошива и сотни начальников, 90 которых даже на работу не '\n",
      "  'ходят, чисто зп получают.\\n',\n",
      "  np.float64(0.9700229400504651)),\n",
      " ('Ты из какого века блядь?', np.float64(0.9689419517586311)),\n",
      " ('да не, там вполне современная, относительно, техника. в квартирах разбитых '\n",
      "  'как раз таки антураж 2013 сервизы и шкафы тех лет)\\n',\n",
      "  np.float64(0.9638205939166433)),\n",
      " ('Ок. Раз уж крахоборничать то пусть будет максимум не - 1 Бар, а - 1,013 '\n",
      "  'Бар. При полной откачке, скажем, воздуха из емкости, на емкость будет '\n",
      "  'воздействовать атмосферное давление, и большее разрежение, чем оно давит, '\n",
      "  'ваккумметр не покажет. То есть максимум - 1 атмосфера, или 1,013 Бар.\\n',\n",
      "  np.float64(0.9627777038043328)),\n",
      " ('Нихуя себе, а у тебя обои как бы не возле розеток находятся??? Какие нахуй '\n",
      "  'провода должны обвивать занавески??? Провода как бы в изоляциии, там '\n",
      "  'никакой искры нет. Нагрев от искры не бывает??? Входит с искрением и искрит '\n",
      "  'постоянно при работе, как бы, чувак, немного отличается. Набрал... '\n",
      "  'Написано-СИЗы, используются для безопасного соединения проводов. ЧО хотел '\n",
      "  'то сказать??? Что аллюминий им не соединишь??? Ну дык, он запрещен сейчас '\n",
      "  'для проводки в помещениях. Быстрозажимные клеммы wago, блядь, для '\n",
      "  'соединения пары проводов под потолком??? Ты реально хоть занимался '\n",
      "  'электромонтажем??? Да никуя ты не занимался, 18 лет мозги ебал. Чувак, ты '\n",
      "  'пойми, соединять в коробке и соединять пару проводов, это разные вещи. '\n",
      "  'Почему? Вопрос в цене, чувак, да!\\n',\n",
      "  np.float64(0.9608454341062642)),\n",
      " ('Конечно. В таком случае, очень рад за вашего оператора, что при должной '\n",
      "  'подготовке он может работать на полную силу, не сдерживаясь и это обоим '\n",
      "  'приносит удовольствие)',\n",
      "  np.float64(0.9602853035419745)),\n",
      " ('У тебя еще есть время\\n', np.float64(0.9550159273080568))]\n"
     ]
    }
   ],
   "source": [
    "counterL = Counter({comm: prob[1] for comm, prob in zip(data.comment, predsL_proba)})\n",
    "L_fin = counterL.most_common(10)\n",
    "pprint(L_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50b0b6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same = list()\n",
    "for i in L_fin:\n",
    "    for j in B_fin:\n",
    "        if i==j and j not in same:\n",
    "            same.append(j)\n",
    "same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e068f",
   "metadata": {},
   "source": [
    "одинаковых текстов нет, тексты действительно токсичные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "628782db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35d009f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['это', 'просто', 'тебе', 'всё', 'вообще']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_importance = clfB.feature_log_prob_[1]\n",
    "featuresB = vectorizerB.get_feature_names_out()\n",
    "toxicB = B_importance.argsort()[-5:][::-1]\n",
    "[featuresB[i] for i in toxicB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "833eceb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['хохлы', 'хохлов', 'тебе', 'дебил', 'нахуй']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_importance = numpy.abs(clfL.coef_[0])\n",
    "featuresL = vectorizerL.get_feature_names_out()\n",
    "toxicL = L_importance.argsort()[-5:][::-1]\n",
    "[featuresL[i] for i in toxicL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7d94b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerRFC = TfidfVectorizer (min_df=4, max_df=0.1, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
    "X_for_RFC = vectorizerRFC.fit_transform(train.comment)\n",
    "X_for_RFC_test = vectorizerRFC.transform(test.comment)\n",
    "\n",
    "vectorizerT = TfidfVectorizer (min_df=4, max_df=0.1, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
    "X_for_T = vectorizerT.fit_transform(train.comment)\n",
    "X_for_T_test = vectorizerT.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89560c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "yRFC = train.toxic.values\n",
    "yRFC_test = test.toxic.values\n",
    "yT = train.toxic.values\n",
    "yT_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4473c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfRFC = RFC(min_samples_leaf = 2, class_weight = 'balanced')\n",
    "clfRFC.fit(X_for_RFC, yRFC)\n",
    "predsRFC = clfRFC.predict(X_for_RFC_test)\n",
    "\n",
    "clfT = T(min_samples_leaf = 2, class_weight = 'balanced')\n",
    "clfT.fit(X_for_T, yT)\n",
    "predsT = clfT.predict(X_for_T_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5db550ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['очень', 'хохлы', 'тебе', 'хохлов', 'спасибо']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_importance = clfRFC.feature_importances_\n",
    "featuresRFC = vectorizerRFC.get_feature_names_out()\n",
    "toxicRFC = RFC_importance.argsort()[-5:][::-1]\n",
    "[featuresRFC[i] for i in toxicRFC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12e61806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['тебе', 'очень', 'хохлы', 'лет', 'всё']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_importance = clfT.feature_importances_\n",
    "featuresT = vectorizerT.get_feature_names_out()\n",
    "toxicT = T_importance.argsort()[-5:][::-1]\n",
    "[featuresT[i] for i in toxicT]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
