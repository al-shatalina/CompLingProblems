{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "129c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier as T\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.naive_bayes import MultinomialNB as bayes\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from razdel import tokenize as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bbaca07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def razdel_tokenizer(text):\n",
    "    return [token.text for token in list(rt(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6873e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "87804ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\scoop\\apps\\python\\current\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['!', '!!', '!!!', ..., 'ёмкостью', 'ёпта', 'ёта'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1 = TfidfVectorizer (tokenizer = razdel_tokenizer)\n",
    "X1 = vectorizer1.fit_transform(train.comment)\n",
    "X1_test = vectorizer1.transform(test.comment)\n",
    "vectorizer1.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fad348ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0015', ..., 'ёмкостью', 'ёпта', 'ёта'], dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2 = TfidfVectorizer () #tokenizer = default\n",
    "X2 = vectorizer2.fit_transform(train.comment)\n",
    "X2_test = vectorizer2.transform(test.comment)\n",
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b56a2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = train.toxic.values\n",
    "y1_test = test.toxic.values\n",
    "y2 = train.toxic.values\n",
    "y2_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d7d27b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.83      0.85       969\n",
      "         1.0       0.68      0.73      0.71       473\n",
      "\n",
      "    accuracy                           0.80      1442\n",
      "   macro avg       0.77      0.78      0.78      1442\n",
      "weighted avg       0.80      0.80      0.80      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RFC(min_samples_leaf = 2, class_weight = 'balanced')\n",
    "clf.fit(X1, y1)\n",
    "preds1 = clf.predict(X1_test)\n",
    "print(classification_report(y1_test, preds1, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff15dc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85       969\n",
      "         1.0       0.69      0.70      0.69       473\n",
      "\n",
      "    accuracy                           0.80      1442\n",
      "   macro avg       0.77      0.77      0.77      1442\n",
      "weighted avg       0.80      0.80      0.80      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RFC(min_samples_leaf = 2, class_weight = 'balanced')\n",
    "clf.fit(X2, y2)\n",
    "preds2 = clf.predict(X2_test)\n",
    "print(classification_report(y2_test, preds2, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3941d33",
   "metadata": {},
   "source": [
    "Встроенный токенизатор побеждает"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2d62b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ac0a5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerL = TfidfVectorizer (min_df=4, max_df=0.1, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
    "X_for_L = vectorizerL.fit_transform(train.comment)\n",
    "X_for_L_test = vectorizerL.transform(test.comment)\n",
    "#vectorizerTF.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "745bd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerB = CountVectorizer (min_df=4, max_df=0.3, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
    "X_for_B = vectorizerB.fit_transform(train.comment)\n",
    "X_for_B_test = vectorizerB.transform(test.comment)\n",
    "#vectorizerC.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5f4f3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "yL = train.toxic.values\n",
    "yL_test = test.toxic.values\n",
    "yB = train.toxic.values\n",
    "yB_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "90311fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.88      0.89       969\n",
      "         1.0       0.76      0.81      0.79       473\n",
      "\n",
      "    accuracy                           0.86      1442\n",
      "   macro avg       0.84      0.85      0.84      1442\n",
      "weighted avg       0.86      0.86      0.86      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfL = LogisticRegression(penalty='l2', class_weight= 'balanced')\n",
    "clfL.fit(X_for_L, yL)\n",
    "predsL = clfL.predict(X_for_L_test)\n",
    "print(classification_report(yL_test, predsL, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "458e2c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.92      0.90       969\n",
      "         1.0       0.82      0.71      0.76       473\n",
      "\n",
      "    accuracy                           0.86      1442\n",
      "   macro avg       0.85      0.82      0.83      1442\n",
      "weighted avg       0.85      0.86      0.85      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfB = bayes(alpha=1, force_alpha=True)\n",
    "clfB.fit(X_for_B, yB)\n",
    "predsB = clfB.predict(X_for_B_test)\n",
    "print(classification_report(yB_test, predsB, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69608f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "predsB_proba = clfB.predict_proba(X_for_B_test)\n",
    "predsL_proba = clfL.predict_proba(X_for_L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1bfad587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8b4ccc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('А вы писать по-докторски умеете?\\n', np.float64(1.0)),\n",
      " ('Истинно так. Но мрии жидов вертят шариком несколько тысяч лет. Мрии хохлов '\n",
      "  'же больше напоминают бредни душевнобольных. Тут я более доверяю иудеям. Они '\n",
      "  'вызывают больше доверия, более ответственны и потенциальны. Мой выбор - '\n",
      "  'жиды.\\n',\n",
      "  np.float64(1.0)),\n",
      " ('а почему с кубани начали, а не с москвы?', np.float64(1.0)),\n",
      " ('Очень даже разделимы. Достаточно знать мотивы гомосексуального поведения у '\n",
      "  'животных (которых Вы, как мне кажется, не знаете), и всё становится на '\n",
      "  'места. А, как Вы выразились, перманентное поведение (т.е. однозначное '\n",
      "  'предпочтение партнёров своего пола и игнорирование партнёров '\n",
      "  'противоположного пола) наблюдалось только у баранов. Пути эволюции, '\n",
      "  'конечно, неисповедимы, но я сомневаюсь, что у геев были бараны среди '\n",
      "  'предков.',\n",
      "  np.float64(1.0)),\n",
      " ('о ужас, не стерпела мужитская психика шума детского и вышел герой в бой '\n",
      "  'неравный, супротив детей и женщин и прогнал он орду поганую на мороз '\n",
      "  'жестокий...\\n',\n",
      "  np.float64(0.9999999996667555)),\n",
      " ('Не дает на 4м свидании-не стоит тратить время.',\n",
      "  np.float64(0.9999999994527116)),\n",
      " ('но тут двое, а там трое. Где ебоболик?', np.float64(0.999999999163002)),\n",
      " ('Но русских из них только двое: остальные - хохлы.\\n',\n",
      "  np.float64(0.9999999989142907)),\n",
      " ('Да мы поняли что ты пидорьё ебаное, поляк наверное. Иди уроки выучи, '\n",
      "  'портфель собери, че ты.\\n',\n",
      "  np.float64(0.9999999960772215)),\n",
      " ('Ага. Селекционеры борщевика были очень ответственные люди',\n",
      "  np.float64(0.9999999940928603))]\n"
     ]
    }
   ],
   "source": [
    "counterB = Counter({comm: prob[1] for comm, prob in zip(data.comment, predsB_proba)})\n",
    "B_fin = counterB.most_common(10)\n",
    "pprint(B_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f433ecce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Действительно, с русским у тебя проблемы. Я тебе уже сказал - свободен, что '\n",
      "  'бля непонятно?Полностью соответствуешь своему нику, осёл. В игнор, '\n",
      "  'нерусь.\\n',\n",
      "  np.float64(0.9788012335263476)),\n",
      " ('Не дает на 4м свидании-не стоит тратить время.',\n",
      "  np.float64(0.9777824457799706)),\n",
      " ('А почему полицаи 23 февраля отмечают? Они ж за немцев были?',\n",
      "  np.float64(0.9773828168071238)),\n",
      " ('Еще раз- ПРОШУ, прочитать мой комментарий. Внимательно.\\n',\n",
      "  np.float64(0.9773580057214164)),\n",
      " ('Шизофазия (речевая разорванность) симптом психических расстройств, '\n",
      "  'выражающийся в нарушении структуры речи, при которой, в отличие от речевой '\n",
      "  'бессвязности (потока несвязанных слов), фразы строятся правильно 1 , однако '\n",
      "  'не несут никакой смысловой нагрузки, а содержание речи соответствует '\n",
      "  'содержанию бреда 2 . Это расстройство речи отражает разорванность мышления '\n",
      "  'пациентов 3 . Это расстройство характерно прежде всего для шизофрении. '\n",
      "  'Понятие шизофазии было введено Э. Крепелином в 1913 году и некоторое время '\n",
      "  'она считалась особой формой шизофрении 4 . Некоторые авторы даже выделяют '\n",
      "  'отдельную форму шизофрении с таким названием 3 . Для шизофазии характерна '\n",
      "  'повышенная речевая активность, речевой напор, а также симптом монолога , '\n",
      "  'характеризующийся речевой неистощимостью и отсутствием потребности в '\n",
      "  'собеседнике 4 . Как правило, этот симптом сочетается с внешней '\n",
      "  'упорядоченностью, доступностью для общения и относительной интеллектуальной '\n",
      "  'и аффективной сохранностью больных 4 . Отличительной чертой шизофазии '\n",
      "  'считаются преимущественная продукция морфемных словообразований и '\n",
      "  'глоссоманиакальных высказываний 5 . Помимо параноидной формы шизофрении 4 '\n",
      "  'она может возникать при тяжёлом слабоумии 6 .\\n',\n",
      "  np.float64(0.9753805449436541)),\n",
      " ('Помню его пожалуй с 50 к подписоты, вроде как то так. Снимал простенько, '\n",
      "  'без вебки, т.е ебалом не светил т было уже норм. Играл в простенькие игры, '\n",
      "  'по типу майна. Самое последнее адекватное видео - было поздравительное на '\n",
      "  '300к подрисчиков, чем-то интересным чтоль веялом, тогда на тытубе не было '\n",
      "  'подобных форматов аля скетчи-влоги, уже не вспомню ну, а дальше пошел '\n",
      "  'полнейший тренд ец, светило ебалом, какие то скетчи со смехуечками естестна '\n",
      "  'не смешными для дерградантов , кривляние. Вообщем, тащемта полная херня, а '\n",
      "  'как увидел что на n-миллионов подрисчиков он устроил какой-то скучный '\n",
      "  'стрим, то нахер отписался и дизу поставил.\\n',\n",
      "  np.float64(0.9739791933725394)),\n",
      " ('Этот сайт - дно Рунета, большинство его посетителей - выродки и отбросы '\n",
      "  'общества. Немногие интеллигенты, ищущие отдушину в анонимном общении также '\n",
      "  'втягиваются в местную маргинальную культуру и быстро деградируют до '\n",
      "  'среднестатистического анонимуса. Так что не ищите здесь уважительного '\n",
      "  'общения без обсценной лексики, его нет.\\n',\n",
      "  np.float64(0.9644313036008023)),\n",
      " ('Там вроде оплата безналом была.', np.float64(0.9621568219962265)),\n",
      " ('Да, я за коммунизм. Парня тебе подбираю Отлично, мне тебя как раз '\n",
      "  'советовали, говорили Более опытного человека в гомосексуализме, среди '\n",
      "  'коммунистов не найдешь так что давай, жду от тебя список гомокоммунистов '\n",
      "  'которых мне предложишь\\n',\n",
      "  np.float64(0.9587540633798824)),\n",
      " ('Истинно так. Но мрии жидов вертят шариком несколько тысяч лет. Мрии хохлов '\n",
      "  'же больше напоминают бредни душевнобольных. Тут я более доверяю иудеям. Они '\n",
      "  'вызывают больше доверия, более ответственны и потенциальны. Мой выбор - '\n",
      "  'жиды.\\n',\n",
      "  np.float64(0.9562050724199582))]\n"
     ]
    }
   ],
   "source": [
    "counterL = Counter({comm: prob[1] for comm, prob in zip(data.comment, predsL_proba)})\n",
    "L_fin = counterL.most_common(10)\n",
    "pprint(L_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "50b0b6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same = list()\n",
    "for i in L_fin:\n",
    "    for j in B_fin:\n",
    "        if i==j and j not in same:\n",
    "            same.append(j)\n",
    "same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e068f",
   "metadata": {},
   "source": [
    "одинаковых текстов нет, тексты действительно токсичные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "35d009f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('всё всё', np.float64(-3.916006829002055)),\n",
       " ('десять лет', np.float64(-5.058790335983302)),\n",
       " ('учли', np.float64(-5.379262231258074)),\n",
       " ('личного', np.float64(-5.739116828114186)),\n",
       " ('устройства', np.float64(-5.745506626212957))]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_tB = Counter({tok: feature\n",
    "        for tok, feature\n",
    "        in zip(\n",
    "            vectorizerB.vocabulary_,\n",
    "            clfB.feature_log_prob_[1]\n",
    "        )}\n",
    ")\n",
    "counter_tB.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833eceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_tL = Counter({tok: feature\n",
    "        for tok, feature\n",
    "        in zip(\n",
    "            vectorizerB.vocabulary_,\n",
    "            #здесь не знаю, что использовать, чтобы получить значения\n",
    "        )}\n",
    ")\n",
    "counter_tL.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7d94b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerRFC = TfidfVectorizer (min_df=4, max_df=0.1, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
    "X_for_RFC = vectorizerRFC.fit_transform(train.comment)\n",
    "X_for_RFC_test = vectorizerRFC.transform(test.comment)\n",
    "\n",
    "vectorizerT = TfidfVectorizer (min_df=4, max_df=0.1, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
    "X_for_T = vectorizerT.fit_transform(train.comment)\n",
    "X_for_T_test = vectorizerT.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "89560c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "yRFC = train.toxic.values\n",
    "yRFC_test = test.toxic.values\n",
    "yT = train.toxic.values\n",
    "yT_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4473c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfRFC = RFC(min_samples_leaf = 2, class_weight = 'balanced')\n",
    "clfRFC.fit(X_for_RFC, yRFC)\n",
    "predsRFC = clfRFC.predict(X_for_RFC_test)\n",
    "\n",
    "clfT = T(min_samples_leaf = 2, class_weight = 'balanced')\n",
    "clfT.fit(X_for_T, yT)\n",
    "predsT = clfT.predict(X_for_T_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5db550ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('коммунизм', np.float64(0.013566331604065696)),\n",
       " ('свалить', np.float64(0.010518633594516874)),\n",
       " ('учли', np.float64(0.010145038801353685)),\n",
       " ('выдержать', np.float64(0.00942615388933382)),\n",
       " ('10 11', np.float64(0.0076900969257069065))]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_tRFC = Counter({tok: feature\n",
    "        for tok, feature\n",
    "        in zip(\n",
    "            vectorizerRFC.vocabulary_,\n",
    "            clfRFC.feature_importances_\n",
    "        )}\n",
    ")\n",
    "counter_tRFC.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "12e61806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('коммунизм', np.float64(0.018218810777401614)),\n",
       " ('учли', np.float64(0.018174531334944483)),\n",
       " ('свалить', np.float64(0.01387441049045727)),\n",
       " ('вероятность', np.float64(0.013387477585772065)),\n",
       " ('похоже это', np.float64(0.011182689848971307))]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_tT = Counter({tok: feature\n",
    "        for tok, feature\n",
    "        in zip(\n",
    "            vectorizerT.vocabulary_,\n",
    "            clfT.feature_importances_\n",
    "        )}\n",
    ")\n",
    "counter_tT.most_common(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
