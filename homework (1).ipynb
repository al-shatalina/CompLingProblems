{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier as T\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.naive_bayes import MultinomialNB as bayes\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from razdel import tokenize as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaca07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def razdel_tokenizer(text):\n",
    "    return [token.text for token in list(rt(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87804ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = TfidfVectorizer (tokenizer = razdel_tokenizer)\n",
    "X1 = vectorizer1.fit_transform(train.comment)\n",
    "X1_test = vectorizer1.transform(test.comment)\n",
    "vectorizer1.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad348ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer () #tokenizer = default\n",
    "X2 = vectorizer2.fit_transform(train.comment)\n",
    "X2_test = vectorizer2.transform(test.comment)\n",
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = train.toxic.values\n",
    "y1_test = test.toxic.values\n",
    "y2 = train.toxic.values\n",
    "y2_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d27b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RFC(min_samples_leaf = 2, class_weight = 'balanced')\n",
    "clf.fit(X1, y1)\n",
    "preds1 = clf.predict(X1_test)\n",
    "print(classification_report(y1_test, preds1, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RFC(min_samples_leaf = 2, class_weight = 'balanced')\n",
    "clf.fit(X2, y2)\n",
    "preds2 = clf.predict(X2_test)\n",
    "print(classification_report(y2_test, preds2, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3941d33",
   "metadata": {},
   "source": [
    "Встроенный токенизатор побеждает"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d62b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerL = TfidfVectorizer (min_df=4, max_df=0.1, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
    "X_for_L = vectorizerL.fit_transform(train.comment)\n",
    "X_for_L_test = vectorizerL.transform(test.comment)\n",
    "#vectorizerTF.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745bd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerB = CountVectorizer (min_df=4, max_df=0.3, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
    "X_for_B = vectorizerB.fit_transform(train.comment)\n",
    "X_for_B_test = vectorizerB.transform(test.comment)\n",
    "#vectorizerC.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "yL = train.toxic.values\n",
    "yL_test = test.toxic.values\n",
    "yB = train.toxic.values\n",
    "yB_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90311fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfL = LogisticRegression(penalty='l2', class_weight= 'balanced')\n",
    "clfL.fit(X_for_L, yL)\n",
    "predsL = clfL.predict(X_for_L_test)\n",
    "print(classification_report(yL_test, predsL, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e2c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfB = bayes(alpha=1, force_alpha=True)\n",
    "clfB.fit(X_for_B, yB)\n",
    "predsB = clfB.predict(X_for_B_test)\n",
    "print(classification_report(yB_test, predsB, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69608f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "predsB_proba = clfB.predict_proba(X_for_B_test)\n",
    "predsL_proba = clfL.predict_proba(X_for_L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfad587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ccc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterB = Counter({comm: prob[1] for comm, prob in zip(data.comment, predsB_proba)})\n",
    "B_fin = counterB.most_common(10)\n",
    "pprint(B_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterL = Counter({comm: prob[1] for comm, prob in zip(data.comment, predsL_proba)})\n",
    "L_fin = counterL.most_common(10)\n",
    "pprint(L_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "same = list()\n",
    "for i in L_fin:\n",
    "    for j in B_fin:\n",
    "        if i==j and j not in same:\n",
    "            same.append(j)\n",
    "same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e068f",
   "metadata": {},
   "source": [
    "одинаковых текстов нет, тексты действительно токсичные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35d009f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('доллары', np.float64(-3.9107735045537746)),\n",
       " ('узнает', np.float64(-5.0052999856993035)),\n",
       " ('пар', np.float64(-5.429284141574706)),\n",
       " ('разбить', np.float64(-5.791313850651098)),\n",
       " ('стране', np.float64(-5.804827569817821))]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_tB = Counter({tok: feature\n",
    "        for tok, feature\n",
    "        in zip(\n",
    "            vectorizerB.vocabulary_,\n",
    "            clfB.feature_log_prob_[1]\n",
    "        )}\n",
    ")\n",
    "counter_tB.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833eceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_tL = Counter({tok: feature\n",
    "        for tok, feature\n",
    "        in zip(\n",
    "            vectorizerB.vocabulary_,\n",
    "            #здесь не знаю, что использовать, чтобы получить значения\n",
    "        )}\n",
    ")\n",
    "counter_tL.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f7d94b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerRFC = TfidfVectorizer (min_df=4, max_df=0.1, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
    "X_for_RFC = vectorizerRFC.fit_transform(train.comment)\n",
    "X_for_RFC_test = vectorizerRFC.transform(test.comment)\n",
    "\n",
    "vectorizerT = TfidfVectorizer (min_df=4, max_df=0.1, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
    "X_for_T = vectorizerT.fit_transform(train.comment)\n",
    "X_for_T_test = vectorizerT.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89560c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "yRFC = train.toxic.values\n",
    "yRFC_test = test.toxic.values\n",
    "yT = train.toxic.values\n",
    "yT_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4473c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfRFC = RFC(min_samples_leaf = 2, class_weight = 'balanced')\n",
    "clfRFC.fit(X_for_RFC, yRFC)\n",
    "predsRFC = clfRFC.predict(X_for_RFC_test)\n",
    "\n",
    "clfT = T(min_samples_leaf = 2, class_weight = 'balanced')\n",
    "clfT.fit(X_for_T, yT)\n",
    "predsT = clfT.predict(X_for_T_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5db550ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('неё', np.float64(0.014246483998346498)),\n",
       " ('станцию', np.float64(0.011806632257174918)),\n",
       " ('передвижения', np.float64(0.009753879273825504)),\n",
       " ('образом', np.float64(0.009735116356764474)),\n",
       " ('говорит это', np.float64(0.00896039996890758))]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_tRFC = Counter({tok: feature\n",
    "        for tok, feature\n",
    "        in zip(\n",
    "            vectorizerRFC.vocabulary_,\n",
    "            clfRFC.feature_importances_\n",
    "        )}\n",
    ")\n",
    "counter_tRFC.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "12e61806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('неё', np.float64(0.017862057041721755)),\n",
       " ('передвижения', np.float64(0.01617632073210278)),\n",
       " ('90х', np.float64(0.015788618411920186)),\n",
       " ('станцию', np.float64(0.014617185990724991)),\n",
       " ('посмотрю', np.float64(0.012095070478296244))]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_tT = Counter({tok: feature\n",
    "        for tok, feature\n",
    "        in zip(\n",
    "            vectorizerT.vocabulary_,\n",
    "            clfT.feature_importances_\n",
    "        )}\n",
    ")\n",
    "counter_tT.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6ce17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
