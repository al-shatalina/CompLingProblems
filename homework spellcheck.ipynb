{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371970ff",
   "metadata": {},
   "source": [
    "# Домашнее задание № 3. Исправление опечаток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67746c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from nltk import sent_tokenize\n",
    "punctuation += \"«»—…“”\"\n",
    "punct = set(punctuation)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe1a76dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = open('data/sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('data/correct_sents.txt', encoding='utf8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa19bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [token.strip(punctuation) for token in tokens_1]\n",
    "    tokens_2 = [token.strip(punctuation) for token in tokens_2]\n",
    "    \n",
    "    tokens_1 = [token for token in tokens_1 if token]\n",
    "    tokens_2 = [token for token in tokens_2 if token]\n",
    "    \n",
    "    assert len(tokens_1) == len(tokens_2)\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cf8bd",
   "metadata": {},
   "source": [
    "## 1. Доп. ранжирование по вероятности (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6be25c",
   "metadata": {},
   "source": [
    "Дополните get_closest_hybrid_match в семинаре так, чтобы из кандадатов с одинаковым расстоянием редактирования выбиралось наиболее вероятное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c74bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n",
    "from difflib import get_close_matches\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f46b6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('data/wiki_data.txt', encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67f8d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_29848\\2167344717.py:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  vocab = Counter(re.findall('\\w+', corpus.lower()))\n"
     ]
    }
   ],
   "source": [
    "vocab = Counter(re.findall('\\w+', corpus.lower()))\n",
    "\n",
    "word2id = list(vocab.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "vec = CountVectorizer(analyzer='char', max_features=10000, ngram_range=(1,3))\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e8814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_with_metric(text, lookup,topn=20, metric=textdistance.levenshtein):\n",
    "    # Counter можно использовать и с не целыми числами\n",
    "    similarities = Counter()\n",
    "    \n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.normalized_similarity(text, word) \n",
    "        \n",
    "    return similarities.most_common(topn)\n",
    "\n",
    "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "\n",
    "    for i in range(1, len(closest)-1):\n",
    "        word = closest[i][0]\n",
    "        s_word = closest[i][1]\n",
    "        prev_word = closest[i-1][0]\n",
    "        s_prev_word = closest[i-1][1]\n",
    "        if s_word == s_prev_word:\n",
    "            p_word = P(word)\n",
    "            p_prev = P(prev_word)\n",
    "            if p_word>p_prev:\n",
    "                closest.pop(i-1)\n",
    "            else:\n",
    "                closest.pop(i)\n",
    "                \n",
    "    return (closest[0])\n",
    "\n",
    "N = sum(vocab.values())\n",
    "\n",
    "def P(word, N=N):\n",
    "    return vocab[word] / N\n",
    "\n",
    "def predict_mistaken(word, vocab):\n",
    "    return 0 if word in vocab else 1\n",
    "\n",
    "def get_closest_match_vec(text, X, vec, topn=20):\n",
    "    v = vec.transform([text])\n",
    "    \n",
    "    similarities = cosine_distances(v, X)[0]\n",
    "    topn = similarities.argsort()[:topn] \n",
    "    \n",
    "    return [(id2word[top], similarities[top]) for top in topn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82b5b248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('солнце', 0.8333333333333334)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match('сонце', X, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac780c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('лестница', 0.875)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match('лесница', X, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ed4a31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 915/915 [08:55<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "mistakes = []\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "cashed = {}\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        if predict_mistaken(pair[1], vocab):\n",
    "            pred = cashed.get(pair[1],get_closest_hybrid_match(pair[1], X, vec)[0])\n",
    "            cashed[pair[1]] = pred\n",
    "        else:\n",
    "            pred = pair[1]\n",
    "        \n",
    "            \n",
    "        if pred == pair[0]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistakes.append((pair[0], pair[1], pred))\n",
    "        total += 1\n",
    "            \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1\n",
    "            if pair[0] != pred:\n",
    "                correct_broken += 1\n",
    "        else:\n",
    "            total_mistaken += 1\n",
    "            if pair[0] == pred:\n",
    "                mistaken_fixed += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a116751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8552276138069035\n",
      "0.48524844720496896\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "print(correct/total)\n",
    "print(mistaken_fixed/total_mistaken)\n",
    "print(correct_broken/total_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf9985",
   "metadata": {},
   "source": [
    "## 2.  Symspell (7 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392cc23",
   "metadata": {},
   "source": [
    "Реализуйте алгоритм Symspell. Он похож на алгоритм Норвига, но проще и быстрее. Он основан только на одной операции - удалении символа. Описание алгоритма по шагам:\n",
    "\n",
    "1) Составляется словарь правильных слов  \n",
    "2) На основе словаря правильных слов составляется словарь удалений - для каждого правильного слова создаются все варианты удалений и создается словарь, где ключ - слово с удалением, а значение - правильное слово  (!) \n",
    "3) Для выбора исправления для слова с опечаткой генерируются все варианты удаления, из них выбираются те, что есть в словаре удалений, построенного на шаге 2. Слово с опечаткой заменяется на правильное слово, соответствующее варианту удаления  \n",
    "4) Если в словаре удалений есть несколько вариантов, то выбирается удаление, которому соответствует наиболее вероятное правильное слово  \n",
    "\n",
    "\n",
    "Оцените качество полученного алгоритма теми же тремя метриками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a298614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_char(word):\n",
    "    char_list=[]\n",
    "    del_word = str()\n",
    "    del_list=[word]\n",
    "    for char in word:\n",
    "        char_list.append(char)\n",
    "    n= len(char_list)\n",
    "    for i in range(n):\n",
    "        new_chars = list(char_list)\n",
    "        new_chars.pop(i)\n",
    "        del_word = ''.join(j for j in new_chars)\n",
    "        del_list.append(del_word)\n",
    "    return del_list \n",
    "\n",
    "#cоставляется словарь правильных слов\n",
    "\n",
    "good_words = set(w for w in vocab)\n",
    "\n",
    "#cоставляется словарь удалений\n",
    "\n",
    "del_dict = dict()\n",
    "for word in good_words:\n",
    "    del_words = del_char(word)\n",
    "    for dword in del_words:\n",
    "        if dword not in del_dict:\n",
    "            del_dict[dword] = {word}\n",
    "        else:\n",
    "            del_dict[dword].add(word)\n",
    "\n",
    "#генерируются все варианты удаления,  выбираются те, что есть в словаре удалений. Слово с опечаткой заменяется на правильное слово, соответствующее варианту удаления\n",
    "\n",
    "def check_Symspell(word):\n",
    "    deleted = del_char(word)\n",
    "    candids = []\n",
    "    for dels in deleted:\n",
    "        for i in del_dict:\n",
    "            if dels == i:\n",
    "                for n in del_dict[i]:\n",
    "                    candids.append(n)\n",
    "    probs_c = dict()\n",
    "    if len(candids)>1:\n",
    "        for c in candids:\n",
    "            c_prob = P(c)\n",
    "            probs_c [c] = c_prob\n",
    "            probs_dict = {k: v for k, v in sorted(probs_c.items(), key=lambda item: item[1], reverse=True)}\n",
    "        res = list(probs_dict.keys())[0]\n",
    "    else:\n",
    "        res = candids\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbb57650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'собака'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_Symspell('сабака')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b3717d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['говорить']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_Symspell('гаворить')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dddab9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 915/915 [15:45<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "mistakes = []\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "cashed = {}\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        if predict_mistaken(pair[1], vocab):\n",
    "            pred = cashed.get(pair[1],check_Symspell(pair[1]))\n",
    "            cashed[pair[1]] = pred\n",
    "        else:\n",
    "            pred = pair[1]\n",
    "        \n",
    "            \n",
    "        if pred == pair[0]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistakes.append((pair[0], pair[1], pred))\n",
    "        total += 1\n",
    "            \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1\n",
    "            if pair[0] != pred:\n",
    "                correct_broken += 1\n",
    "        else:\n",
    "            total_mistaken += 1\n",
    "            if pair[0] == pred:\n",
    "                mistaken_fixed += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65a19bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8212106053026513\n",
      "0.22127329192546583\n",
      "0.09004249454461927\n"
     ]
    }
   ],
   "source": [
    "print(correct/total)\n",
    "print(mistaken_fixed/total_mistaken)\n",
    "print(correct_broken/total_correct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
